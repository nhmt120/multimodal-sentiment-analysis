{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"SEED = 61\n\nimport numpy as np\nimport tensorflow as tf\nimport random as python_random\nimport os\n\ndef reset_seeds():\n    np.random.seed(SEED) \n    python_random.seed(SEED)\n    tf.random.set_seed(SEED)\n    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n    \nimport os\nimport re\nimport gc\nimport tensorflow_addons as tfa\nimport h5py\nimport torch\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom nltk import tokenize\n\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n\nfrom keras import backend as K\nfrom keras import initializers,regularizers,constraints\nfrom keras.preprocessing.text import Tokenizer, text_to_word_sequence\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils.np_utils import to_categorical\nfrom keras.layers import Reshape, Input, Embedding, Flatten, Dense, Dropout, BatchNormalization, Activation #, merge\nfrom keras.layers import TimeDistributed, LSTM, GRU, Bidirectional, Convolution1D, MaxPooling1D, MaxPooling2D\nfrom keras.layers.core import RepeatVector #, Reshape\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.models import Sequential, Model, load_model\nfrom sklearn.model_selection import RepeatedKFold, KFold\nfrom sklearn.model_selection import cross_val_score\n\nfrom tensorflow.python.keras.layers import Layer, InputSpec, Lambda\n\nfrom transformers import BertTokenizer, BertForMaskedLM, BertModel\n\n# from tensorflow.keras import Model\n# from attention import Attention_input1, Attention_input2\n# from keras.optimizers import SGD, RMSprop, Adagrad","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-30T20:14:12.119687Z","iopub.execute_input":"2022-06-30T20:14:12.120167Z","iopub.status.idle":"2022-06-30T20:14:26.204590Z","shell.execute_reply.started":"2022-06-30T20:14:12.120129Z","shell.execute_reply":"2022-06-30T20:14:26.203394Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def read_hdf5(path):\n    read_file = h5py.File(path, 'r')\n    \n    feature_names = list(read_file.keys())\n    loaded_data = []\n    \n    for name in feature_names:\n        dataset = read_file[name][:]\n        if dataset.dtype == np.dtype('object'):\n            dataset = np.array([x.decode('UTF-8') for x in dataset])            \n        loaded_data.append((name, dataset))\n\n    return loaded_data\n\ndef loadz(path):\n    data = np.load(path)['arr_0']\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:13:02.726684Z","iopub.execute_input":"2022-06-30T18:13:02.727341Z","iopub.status.idle":"2022-06-30T18:13:02.735753Z","shell.execute_reply.started":"2022-06-30T18:13:02.727304Z","shell.execute_reply":"2022-06-30T18:13:02.734408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_labels(path):\n    data = read_hdf5(path)\n\n    for x in data:\n        if x[0] == 'multimodal-labels':\n            labels = x[1]\n        if x[0] == 'text-labels':\n            text_labels = x[1]\n        if x[0] == 'image-labels':\n            image_labels = x[1]\n        \n    return labels, text_labels, image_labels\n\ndef merge_mvsa(mvsa_single, mvsa_multiple):\n    mvsa = np.concatenate((mvsa_single, mvsa_multiple), axis=0)\n    return mvsa\n\ndef load_mvsa_feature(feature_name, merge=False):\n    folder_path = os.path.join('../input/mvsa-features/', feature_name)\n    single_file = 'mvsa-single-{}.npz'.format(feature_name)\n    multiple_file = 'mvsa-multiple-{}.npz'.format(feature_name)\n    mvsa_single = loadz(os.path.join(folder_path, single_file))\n    mvsa_multiple = loadz(os.path.join(folder_path, multiple_file))\n    \n    if merge == True:\n        return merge_mvsa(mvsa_single, mvsa_multiple)\n    \n    return mvsa_single, mvsa_multiple","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:13:43.736632Z","iopub.execute_input":"2022-06-30T18:13:43.736996Z","iopub.status.idle":"2022-06-30T18:13:43.747116Z","shell.execute_reply.started":"2022-06-30T18:13:43.736967Z","shell.execute_reply":"2022-06-30T18:13:43.746088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# e.g. validation_split=0.1 -----> 8:1:1 ratio of train, val, test\ndef split_data(data, validation_split):\n    num_val = int(validation_split * data.shape[0])\n    data_train = data[:-(num_val*2)]\n    data_val = data[-(num_val*2):-(num_val)]\n    data_test = data[-num_val:]\n    return data_train, data_val, data_test","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:13:02.754024Z","iopub.execute_input":"2022-06-30T18:13:02.754338Z","iopub.status.idle":"2022-06-30T18:13:02.761271Z","shell.execute_reply.started":"2022-06-30T18:13:02.754308Z","shell.execute_reply":"2022-06-30T18:13:02.760312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model_IF(text_shape, image_shape):\n    f1_score = tfa.metrics.F1Score(num_classes=NUM_CLASSES, average='macro')\n    \n    image_input = Input(shape=image_shape)\n    text_input = Input(shape=text_shape)\n    text_reshape = Reshape((1, -1)) (text_input)\n    text_lstm = Bidirectional(LSTM(DIM_LSTM)) (text_reshape)\n    text_lstm = Dropout(DROPOUT_RATE) (text_lstm)\n    text_image_concat = tf.keras.layers.Concatenate(axis=1)([text_lstm, image_input])\n    concat_self_attention = tf.keras.layers.Attention() ([text_image_concat, text_image_concat])\n    concat_self_attention = Dropout(DROPOUT_RATE) (concat_self_attention)\n    concat_softmax = Dense(NUM_CLASSES, activation='softmax') (concat_self_attention)\n    \n    model = Model([text_input, image_input], concat_softmax)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score]) # f1 #tf.keras.metrics.AUC()\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:43:06.792883Z","iopub.execute_input":"2022-06-30T18:43:06.793740Z","iopub.status.idle":"2022-06-30T18:43:06.803348Z","shell.execute_reply.started":"2022-06-30T18:43:06.793704Z","shell.execute_reply":"2022-06-30T18:43:06.802316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model_image(input_shape):\n    f1_score = tfa.metrics.F1Score(num_classes=NUM_CLASSES, average='macro')\n    \n    image_input = Input(shape=input_shape)\n    outputs = Dense(NUM_CLASSES, activation='softmax') (image_input)\n    \n    model = Model(image_input, outputs)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score]) # f1 #tf.keras.metrics.AUC()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:36:02.390333Z","iopub.execute_input":"2022-06-30T19:36:02.390832Z","iopub.status.idle":"2022-06-30T19:36:02.424573Z","shell.execute_reply.started":"2022-06-30T19:36:02.390736Z","shell.execute_reply":"2022-06-30T19:36:02.423708Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def create_model_text(input_shape):\n    f1_score = tfa.metrics.F1Score(num_classes=NUM_CLASSES, average='macro')\n    \n    text_input = Input(shape=input_shape)\n    reshape_text = Reshape((1, -1)) (text_input)\n    lstm = LSTM(NUM_LSTM) (reshape_text)\n    outputs = Dense(NUM_CLASSES, activation='softmax') (lstm)\n    \n    model = Model(text_input, outputs)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score]) # f1 #tf.keras.metrics.AUC()\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:46:14.056655Z","iopub.execute_input":"2022-06-30T19:46:14.057702Z","iopub.status.idle":"2022-06-30T19:46:14.065234Z","shell.execute_reply.started":"2022-06-30T19:46:14.057644Z","shell.execute_reply":"2022-06-30T19:46:14.063886Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, X_texts, X_images, y_test, checkpoint=None, verbose=1):\n    if checkpoint is not None:\n        model = load_model('./model_checkpoint/{}.h5'.format(checkpoint))#, custom_objects={'f1': f1})\n    \n    loss, acc, f1 = model.evaluate([X_texts, X_images], y_test, verbose=verbose)\n\n    if verbose == 1:\n        print('Loss:', loss)\n        print('Accuracy:', acc)\n        print('F1-score:', f1)\n        y_pred = model.predict([X_texts, X_images])\n        matrix = confusion_matrix(le.inverse_transform(y_test.argmax(axis=1)), le.inverse_transform(y_pred.argmax(axis=1)), \n                                  labels=list(le.classes_))\n        cm_disp = ConfusionMatrixDisplay(confusion_matrix=matrix,\n                                  display_labels=list(le.classes_))\n        cm_disp.plot()\n        plt.show()\n        \n    return loss, acc, f1","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:00:51.305316Z","iopub.execute_input":"2022-06-30T19:00:51.306005Z","iopub.status.idle":"2022-06-30T19:00:51.315623Z","shell.execute_reply.started":"2022-06-30T19:00:51.305965Z","shell.execute_reply":"2022-06-30T19:00:51.314184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_and_evaluate(name, X1, X2, y, verbose=0):\n    ''' \n    X1: text input\n    X2: image input\n    '''\n    y = le.fit_transform(y)\n    y = to_categorical(np.asarray(y))\n    \n    X1_train, X1_val, X1_test = split_data(X1, VALIDATION_SPLIT)\n    X2_train, X2_val, X2_test = split_data(X2, VALIDATION_SPLIT)\n    y_train, y_val, y_test = split_data(y, VALIDATION_SPLIT)\n    \n    model = create_model_IF(X1_train.shape[1:], X2_train.shape[1:])\n    early_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n    checkpoint = ModelCheckpoint('./model_checkpoint/{}.h5'.format(name), save_best_only=True, verbose=verbose)\n    \n    history = model.fit([X1_train, X2_train], y_train, validation_data=([X1_val, X2_val], y_val), \n                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n                        callbacks=[checkpoint, early_stopping])\n    print('Early stopped at epoch:', early_stopping.stopped_epoch)\n    return history, evaluate_model(model, X1_test, X2_test, y_test, checkpoint=name, verbose=verbose)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:32:04.871210Z","iopub.execute_input":"2022-06-30T18:32:04.871605Z","iopub.status.idle":"2022-06-30T18:32:04.882322Z","shell.execute_reply.started":"2022-06-30T18:32:04.871571Z","shell.execute_reply":"2022-06-30T18:32:04.881168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history):\n    fig = plt.figure(figsize=(20, 5))\n\n    fig.add_subplot(1, 3, 1)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('LOSS')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='best')\n\n    fig.add_subplot(1, 3, 2)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('ACCURACY')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='best')\n\n    fig.add_subplot(1, 3, 3)\n    plt.plot(history.history['f1_score'])\n    plt.plot(history.history['val_f1_score'])\n    plt.title('F1-SCORE')\n    plt.ylabel('f1-score')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='best')\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:38:14.737716Z","iopub.execute_input":"2022-06-30T18:38:14.738059Z","iopub.status.idle":"2022-06-30T18:38:14.748383Z","shell.execute_reply.started":"2022-06-30T18:38:14.738023Z","shell.execute_reply":"2022-06-30T18:38:14.747413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"## Choose best\n# Load text feature\nmvsa_single_bert_base, mvsa_multiple_bert_base = load_mvsa_feature('bert-base')\nmvsa_single_pos_bow, mvsa_multiple_pos_bow = load_mvsa_feature('pos-bow')\n# mvsa_single_pos_tfidf, mvsa_multiple_pos_tfidf = load_mvsa_feature('pos-tfidf')\n# mvsa_single_ner_bow, mvsa_multiple_ner_bow = load_mvsa_feature('ner-bow')\n# mvsa_single_ner_tfidf, mvsa_multiple_ner_tfidf = load_mvsa_feature('ner-tfidf')\n\n## Load image feature\n# mvsa_single_vgg16, mvsa_multiple_vgg16 = load_mvsa_feature('vgg16')\n# mvsa_single_vgg19, mvsa_multiple_vgg19 = load_mvsa_feature('vgg19')\n# mvsa_single_resnet50, mvsa_multiple_resnet50 = load_mvsa_feature('resnet50')\n# mvsa_single_resnet101, mvsa_multiple_resnet101 = load_mvsa_feature('resnet101')\n# mvsa_single_resnet152, mvsa_multiple_resnet152 = load_mvsa_feature('resnet152')\n# mvsa_single_densenet121, mvsa_multiple_densenet121 = load_mvsa_feature('densenet121')\n# mvsa_single_densenet169, mvsa_multiple_densenet169 = load_mvsa_feature('densenet169')\nmvsa_single_densenet201, mvsa_multiple_densenet201 = load_mvsa_feature('densenet201')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:13:48.125867Z","iopub.execute_input":"2022-06-30T18:13:48.126727Z","iopub.status.idle":"2022-06-30T18:13:51.740350Z","shell.execute_reply.started":"2022-06-30T18:13:48.126691Z","shell.execute_reply":"2022-06-30T18:13:51.739351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mvsa_single_multimodal_labels, mvsa_single_text_labels, mvsa_single_image_labels = load_labels('../input/mvsa-features/labels/mvsa-single-labels.hdf5')\nmvsa_multiple_multimodal_labels, mvsa_multiple_text_labels, mvsa_multiple_image_labels = load_labels('../input/mvsa-features/labels/mvsa-multiple-labels.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:14:05.547305Z","iopub.execute_input":"2022-06-30T18:14:05.548507Z","iopub.status.idle":"2022-06-30T18:14:05.699033Z","shell.execute_reply.started":"2022-06-30T18:14:05.548414Z","shell.execute_reply":"2022-06-30T18:14:05.698020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mvsa_single_text_features = np.concatenate((mvsa_single_bert_base, mvsa_single_pos_bow), axis=1)\nmvsa_multiple_text_features = np.concatenate((mvsa_multiple_bert_base, mvsa_multiple_pos_bow), axis=1)\n\nmvsa_single_image_features = mvsa_single_densenet201\nmvsa_multiple_image_features = mvsa_multiple_densenet201\n\nprint('Text vector shape:', mvsa_single_text_features.shape[1:])\nprint('Image vector shape:', mvsa_single_image_features.shape[1:])","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:35:25.851109Z","iopub.execute_input":"2022-06-30T18:35:25.852095Z","iopub.status.idle":"2022-06-30T18:35:25.897306Z","shell.execute_reply.started":"2022-06-30T18:35:25.852057Z","shell.execute_reply":"2022-06-30T18:35:25.896302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nle.fit(mvsa_single_multimodal_labels)\nNUM_CLASSES = len(le.classes_) # = 3","metadata":{"execution":{"iopub.status.busy":"2022-06-30T18:16:21.788111Z","iopub.execute_input":"2022-06-30T18:16:21.788515Z","iopub.status.idle":"2022-06-30T18:16:21.795204Z","shell.execute_reply.started":"2022-06-30T18:16:21.788480Z","shell.execute_reply":"2022-06-30T18:16:21.793848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reset_seeds()\nEPOCHS = 100\nBATCH_SIZE = 1000\nVALIDATION_SPLIT = 0.1\nEARLY_STOPPING = 100\nDIM_LSTM = 128\nDROPOUT_RATE = 0.1","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:13:40.129423Z","iopub.execute_input":"2022-06-30T19:13:40.130093Z","iopub.status.idle":"2022-06-30T19:13:40.158198Z","shell.execute_reply.started":"2022-06-30T19:13:40.130057Z","shell.execute_reply":"2022-06-30T19:13:40.157114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history, scores = run_and_evaluate('bertpb-densenet201', mvsa_single_text_features, mvsa_single_image_features, mvsa_single_multimodal_labels, verbose=1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-30T19:13:40.808506Z","iopub.execute_input":"2022-06-30T19:13:40.809287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_metrics(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T19:13:09.457768Z","iopub.execute_input":"2022-06-30T19:13:09.458127Z","iopub.status.idle":"2022-06-30T19:13:09.866273Z","shell.execute_reply.started":"2022-06-30T19:13:09.458097Z","shell.execute_reply":"2022-06-30T19:13:09.865343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model_LF(text_shape, image_shape):\n    f1_score = tfa.metrics.F1Score(num_classes=NUM_CLASSES, average='macro')\n    \n    model_text = create_model_text(text_shape)\n    model_text.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score]) # f1 #tf.keras.metrics.AUC()\n\n    model_image = create_model_image(image_shape)\n    model_image.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score]) # f1 #tf.keras.metrics.AUC()\n    \n    return model_text, model_image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_and_evaluate(name, X1, X2, y, verbose=0):\n    ''' \n    X1: text input\n    X2: image input\n    '''\n    y = le.fit_transform(y)\n    y = to_categorical(np.asarray(y))\n    \n    X1_train, X1_val, X1_test = split_data(X1, VALIDATION_SPLIT)\n    X2_train, X2_val, X2_test = split_data(X2, VALIDATION_SPLIT)\n    y_train, y_val, y_test = split_data(y, VALIDATION_SPLIT)\n    \n    model = create_model_IF(X1_train.shape[1:], X2_train.shape[1:])\n    early_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n    checkpoint = ModelCheckpoint('./model_checkpoint/{}.h5'.format(name), save_best_only=True, verbose=verbose)\n    \n    history = model.fit([X1_train, X2_train], y_train, validation_data=([X1_val, X2_val], y_val), \n                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n                        callbacks=[checkpoint, early_stopping])\n    print('Early stopped at epoch:', early_stopping.stopped_epoch)\n    return history, evaluate_model(model, X1_test, X2_test, y_test, checkpoint=name, verbose=verbose)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_and_evaluate_LF(name, X1, X2, y, verbose=0):\n    ''' \n    X1: text input\n    X2: image input\n    '''\n    y = le.fit_transform(y)\n    y = to_categorical(np.asarray(y))\n    \n    X1_train, X1_val, X1_test = split_data(X1, VALIDATION_SPLIT)\n    X2_train, X2_val, X2_test = split_data(X2, VALIDATION_SPLIT)\n    y_train, y_val, y_test = split_data(y, VALIDATION_SPLIT)\n    \n    model_text = create_model_text(X1_train.shape[1:])\n    model_image = create_model_image(X2_train.shape[1:])\n\n    early_stopping1 = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n    early_stopping2 = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n    checkpoint_text = ModelCheckpoint('./model_checkpoint/{}.h5'.format(name + '-text'), save_best_only=True, verbose=verbose)\n    checkpoint_image = ModelCheckpoint('./model_checkpoint/{}.h5'.format(name + '-image'), save_best_only=True, verbose=verbose)\n    \n    history_text = model_text.fit(X1_train, y_train, validation_data=(X1_val, y_val), \n                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n                        callbacks=[checkpoint_text, early_stopping1])\n    \n    history_image = model_image.fit(X2_train, y_train, validation_data=(X2_val, y_val), \n                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n                        callbacks=[checkpoint_image, early_stopping2])\n    \n    best_loss_text = np.min(history_text.history['val_loss'])\n    best_loss_image = np.min(history_image.history['val_loss'])\n\n    weight_text = best_loss_text / (best_loss_text + best_loss_image)\n    weight_image = best_loss_image / (best_loss_text + best_loss_image)\n\n    y_pred_text = model_text.predict(X1_test)\n    y_pred_image = model_text.predict(X2_test)\n    \n    \n    \n    print('Text model early stopped at epoch:', early_stopping1.stopped_epoch)\n    print('Image model early stopped at epoch:', early_stopping2.stopped_epoch)\n\n    \n    return history, evaluate_model(model, X1_test, X2_test, y_test, checkpoint=name, verbose=verbose)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drafts","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def f1(y_true, y_pred): #taken from old keras source code\n#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n#     precision = true_positives / (predicted_positives + K.epsilon())\n#     recall = true_positives / (possible_positives + K.epsilon())\n#     f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n#     return f1_val","metadata":{},"execution_count":null,"outputs":[]}]}