{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vincemarcs/mvsa-fusion-models-ml?scriptVersionId=143429506\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install keras-self-attention","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:07.805889Z","iopub.execute_input":"2022-08-12T17:37:07.8068Z","iopub.status.idle":"2022-08-12T17:37:24.23581Z","shell.execute_reply.started":"2022-08-12T17:37:07.806668Z","shell.execute_reply":"2022-08-12T17:37:24.234445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 61\n\nimport os\nimport re\nimport gc\nimport h5py\nimport torch\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport random as python_random\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom nltk import tokenize\nfrom IPython.display import display_html\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom keras_self_attention import SeqSelfAttention\nfrom transformers import BertTokenizer, BertForMaskedLM, BertModel\nfrom tensorflow.python.keras.layers import Layer, InputSpec, Lambda\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import RepeatedKFold, KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n\nfrom keras import backend as K\nfrom keras import initializers,regularizers,constraints\nfrom keras.preprocessing.text import Tokenizer, text_to_word_sequence\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils.np_utils import to_categorical\nfrom keras.layers import Reshape, Input, Embedding, Flatten, Dense, Dropout, BatchNormalization, Activation #, merge\nfrom keras.layers import TimeDistributed, LSTM, GRU, Bidirectional, Convolution1D, MaxPooling1D, MaxPooling2D, GlobalMaxPooling1D\nfrom keras.layers.core import RepeatVector #, Reshape\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.models import Sequential, Model, load_model\n\ndef reset_seeds():\n    np.random.seed(SEED) \n    python_random.seed(SEED)\n    tf.random.set_seed(SEED)\n    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n\n# from tensorflow.keras import Model\n# from attention import Attention_input1, Attention_input2\n# from keras.optimizers import SGD, RMSprop, Adagrad","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-12T17:37:24.239608Z","iopub.execute_input":"2022-08-12T17:37:24.24019Z","iopub.status.idle":"2022-08-12T17:37:38.49991Z","shell.execute_reply.started":"2022-08-12T17:37:24.24013Z","shell.execute_reply":"2022-08-12T17:37:38.498656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_hdf5(path):\n    read_file = h5py.File(path, 'r')\n    \n    feature_names = list(read_file.keys())\n    loaded_data = []\n    \n    for name in feature_names:\n        dataset = read_file[name][:]\n        if dataset.dtype == np.dtype('object'):\n            dataset = np.array([x.decode('UTF-8') for x in dataset])            \n        loaded_data.append((name, dataset))\n\n    return loaded_data\n\ndef loadz(path):\n    data = np.load(path)['arr_0']\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:38.501395Z","iopub.execute_input":"2022-08-12T17:37:38.502099Z","iopub.status.idle":"2022-08-12T17:37:38.512155Z","shell.execute_reply.started":"2022-08-12T17:37:38.502059Z","shell.execute_reply":"2022-08-12T17:37:38.51111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_labels(path):\n    data = read_hdf5(path)\n\n    for x in data:\n        if x[0] == 'multimodal-labels':\n            labels = x[1]\n        if x[0] == 'text-labels':\n            text_labels = x[1]\n        if x[0] == 'image-labels':\n            image_labels = x[1]\n\n    return labels, text_labels, image_labels\n\ndef merge_mvsa(mvsa_single, mvsa_multiple):\n    mvsa = np.concatenate((mvsa_single, mvsa_multiple), axis=0)\n    return mvsa\n\ndef load_mvsa_feature(feature_name, merge=False):\n    folder_path = os.path.join('../input/mvsa-features/', feature_name)\n    single_file = 'mvsa-single-{}.npz'.format(feature_name)\n    multiple_file = 'mvsa-multiple-{}.npz'.format(feature_name)\n    mvsa_single = loadz(os.path.join(folder_path, single_file))\n    mvsa_multiple = loadz(os.path.join(folder_path, multiple_file))\n    \n    if merge == True:\n        return merge_mvsa(mvsa_single, mvsa_multiple)\n    \n    return mvsa_single, mvsa_multiple","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:38.514947Z","iopub.execute_input":"2022-08-12T17:37:38.51701Z","iopub.status.idle":"2022-08-12T17:37:38.556713Z","shell.execute_reply.started":"2022-08-12T17:37:38.516954Z","shell.execute_reply":"2022-08-12T17:37:38.555507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features(feature_names):\n    mvsa_single_features = []\n    mvsa_multiple_features = []\n\n    for name in feature_names:\n        \n        name_split = name.split('-')\n        textual = name_split[1]\n        visual = name_split[0]\n        \n        if textual == 'bert':\n            textual = 'bert-base'\n\n        textual_features = load_mvsa_feature(textual)\n        visual_features = load_mvsa_feature(visual)\n\n        if 'pos' in name and 'ner' not in name:\n            temp = []\n            pos_features = load_mvsa_feature('pos-tfidf')\n            temp.append(np.concatenate((textual_features[0], pos_features[0]), axis=1))\n            temp.append(np.concatenate((textual_features[1], pos_features[1]), axis=1))\n            textual_features = temp\n\n        elif 'pos' not in name and 'ner' in name:\n            temp = []\n            ner_features = load_mvsa_feature('ner-tfidf')\n            temp.append(np.concatenate((textual_features[0], ner_features[0]), axis=1))\n            temp.append(np.concatenate((textual_features[1], ner_features[1]), axis=1))\n            textual_features = temp\n\n        elif 'pos' in name and 'ner' in name:\n            temp = []\n            pos_features = load_mvsa_feature('pos-tfidf')\n            ner_features = load_mvsa_feature('ner-tfidf')\n            temp.append(np.concatenate((textual_features[0], pos_features[0], ner_features[0]), axis=1))\n            temp.append(np.concatenate((textual_features[1], pos_features[1], ner_features[1]), axis=1))\n            textual_features = temp\n\n        mvsa_single_features.append([textual_features[0], visual_features[0]])\n        mvsa_multiple_features.append([textual_features[1], visual_features[1]])\n\n    return mvsa_single_features, mvsa_multiple_features","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:38.558139Z","iopub.execute_input":"2022-08-12T17:37:38.559356Z","iopub.status.idle":"2022-08-12T17:37:38.573551Z","shell.execute_reply.started":"2022-08-12T17:37:38.55931Z","shell.execute_reply":"2022-08-12T17:37:38.572595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# e.g. validation_split=0.1 -----> 8:1:1 ratio of train, val, test\ndef split_data(data, validation_split):\n    num_val = int(validation_split * data.shape[0])\n    data_train = data[:-(num_val*2)]\n    data_val = data[-(num_val*2):-(num_val)]\n    data_test = data[-num_val:]\n    return data_train, data_val, data_test","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:38.574983Z","iopub.execute_input":"2022-08-12T17:37:38.576291Z","iopub.status.idle":"2022-08-12T17:37:38.587453Z","shell.execute_reply.started":"2022-08-12T17:37:38.576238Z","shell.execute_reply":"2022-08-12T17:37:38.586574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shuffle_mvsa(mvsa_features, labels, indices):\n    shuffled_features = []\n#     random_idx = np.random.permutation(len(labels))\n    for i in range(len(mvsa_features)):\n        x, y = mvsa_features[i][0][indices], mvsa_features[i][1][indices]\n        shuffled_features.append([x, y])\n    return shuffled_features, labels[indices]\n\ndef preprocess_inputs(X1, X2, y, smote):\n    y = le.fit_transform(y)\n    y = to_categorical(np.asarray(y))\n\n    X1_train, X1_val, X1_test = split_data(X1, VALIDATION_SPLIT)\n    X2_train, X2_val, X2_test = split_data(X2, VALIDATION_SPLIT)\n    y_train, y_val, y_test = split_data(y, VALIDATION_SPLIT)\n    \n    if smote == True:\n#         oversample = BorderlineSMOTE(sampling_strategy='minority', random_state=SEED, kind='borderline-2')\n        oversample = SMOTE(sampling_strategy='minority', random_state=SEED)\n        X1_train, _ = oversample.fit_resample(X1_train, y_train)\n        X2_train, y_train = oversample.fit_resample(X2_train, y_train)\n\n    return {'texts': [X1_train, X1_val, X1_test], 'images': [X2_train, X2_val, X2_test], 'labels':[y_train, y_val, y_test]}\n\n# def get_preprocess_input(feature_names, mvsa_features, labels):\n#     mvsa_features_shuffled, labels_shuffled = shuffle_mvsa(mvsa_features, labels)\n#     mvsa_features_split = []\n#     for i in range(len(feature_names)):\n#         preprocess_splits = preprocess_inputs(mvsa_features_shuffled[i][0], mvsa_features_shuffled[i][1], labels_shuffled)\n#         mvsa_features_split.append(preprocess_splits)\n#     return mvsa_features_split\n\ndef process_dup(names):\n    new_names = []\n    for i in range(len(names)):\n        count_dup = 0\n        for j in range(0, i+1):\n            if names[i] == names[j]:\n                count_dup += 1\n        if count_dup > 1:\n            new_names.append(names[i] + '-' + str(count_dup))\n        else:\n            new_names.append(names[i])\n    return new_names","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:38.589204Z","iopub.execute_input":"2022-08-12T17:37:38.589926Z","iopub.status.idle":"2022-08-12T17:37:38.605589Z","shell.execute_reply.started":"2022-08-12T17:37:38.58988Z","shell.execute_reply":"2022-08-12T17:37:38.604296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_CLASSES = 3\nf1_macro = tfa.metrics.F1Score(num_classes=NUM_CLASSES, average='macro', name='f1_macro')\nf1_weighted = tfa.metrics.F1Score(num_classes=NUM_CLASSES, average='weighted', name='f1_weighted')\n    \ndef create_model_text(input_shape, lstm=True):\n    text_input = Input(shape=input_shape)\n    dropout = Dropout(DROPOUT_INPUT) (text_input)\n    if lstm == True:\n        text_reshape = Reshape((1, -1)) (dropout)\n        text_lstm = LSTM(NUM_LSTM) (text_reshape)\n        dropout = Dropout(DROPOUT_LSTM) (text_lstm)\n    outputs = Dense(NUM_CLASSES, activation='softmax') (dropout)\n    model = Model(text_input, outputs)\n    model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=['accuracy', f1_macro, f1_weighted])\n    return model\n\ndef create_model_image(input_shape, lstm=True):\n    image_input = Input(shape=input_shape)\n    dropout = Dropout(DROPOUT_INPUT_IMG) (image_input)    \n#     if lstm == True:\n#         image_reshape = Reshape((1, -1)) (dropout)\n#         image_lstm = LSTM(NUM_LSTM_IMG) (image_reshape)\n#         dropout = Dropout(DROPOUT_LSTM_IMG) (image_lstm)\n    outputs = Dense(NUM_CLASSES, activation='softmax') (dropout)\n    model = Model(image_input, outputs)\n    model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=['accuracy', f1_macro, f1_weighted])\n    return model\n\ndef create_model_IF(text_shape, image_shape, lstm=True):\n    text_input = Input(shape=text_shape)\n    image_input = Input(shape=image_shape)\n    \n    text_dropout = Dropout(DROPOUT_INPUT) (text_input)    \n    image_dropout = Dropout(DROPOUT_INPUT_IMG) (image_input)    \n\n    if lstm == True:\n        text_reshape = Reshape((1, -1)) (text_dropout)\n        text_lstm = LSTM(NUM_LSTM) (text_reshape)\n        text_dropout = Dropout(DROPOUT_LSTM) (text_lstm)\n\n#         image_reshape = Reshape((1, -1)) (image_dropout)\n#         image_lstm = LSTM(NUM_LSTM_IMG) (image_reshape)\n#         image_dropout = Dropout(DROPOUT_LSTM_IMG) (image_lstm)\n\n    text_image_concat = tf.keras.layers.Concatenate(axis=1)([text_dropout, image_dropout])\n    concat_reshape = Reshape((1, -1)) (text_image_concat)\n    self_attention = SeqSelfAttention() (concat_reshape)\n    dropout = Dropout(DROPOUT_ATT) (self_attention)\n    flatten = GlobalMaxPooling1D () (self_attention)\n    outputs = Dense(NUM_CLASSES, activation='softmax') (flatten)\n    model = Model([text_input, image_input], outputs)\n    model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=['accuracy', f1_macro, f1_weighted])\n    return model","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-12T17:37:38.607527Z","iopub.execute_input":"2022-08-12T17:37:38.608356Z","iopub.status.idle":"2022-08-12T17:37:38.991259Z","shell.execute_reply.started":"2022-08-12T17:37:38.608302Z","shell.execute_reply":"2022-08-12T17:37:38.990354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weighted_average(weights, probs):\n    ''' Calculate the weighted average probability distribution from all input probs and its weights \n    weights: weights list (or array)\n    probs: probability distributions array list\n    '''\n    output_probs = []\n    weighted_probs = [probs[i] * weights[i] for i in range(len(weights))]\n    for i in range(len(probs[0])):\n        sum_prob = np.zeros(len(probs[0][0]))\n        for j in range(len(weights)):\n            sum_prob = np.sum((sum_prob, weighted_probs[j][i]), axis=0)\n        output_probs.append(sum_prob)\n    return np.asarray(output_probs, dtype='float32')\n\ndef get_average_weights(*scores, inverse=False):\n    ''' Get the corresponding weight of each input score \n    inverse: (bool) get inverse weights value in case of the smaller score value, the bigger weight value (such as model loss)\n    '''\n    \n    weights = []\n    for score in scores:\n        weights.append(score/np.sum(scores))\n    \n    if inverse == True:\n        inverse_weights = []\n        inverse = [1/weight for weight in weights]\n        for inv in inverse:\n            inverse_weights.append(inv/np.sum(inverse))\n        weights = inverse_weights\n\n    return weights","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:38.992661Z","iopub.execute_input":"2022-08-12T17:37:38.993885Z","iopub.status.idle":"2022-08-12T17:37:39.004501Z","shell.execute_reply.started":"2022-08-12T17:37:38.993845Z","shell.execute_reply":"2022-08-12T17:37:39.003504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_and_evaluate_IF(name, X1, X2, y, verbose=0, lstm=True):\n\n    if 'multiple' in name:\n        batch_size = BATCH_SIZE_MULTIPLE\n        if DO_SMOTE_MULTIPLE == True:\n            smote = True\n        else:\n            smote = False\n    else:\n        batch_size = BATCH_SIZE_SINGLE # 128\n        if DO_SMOTE_SINGLE == True:\n            smote = True\n        else:\n            smote = False\n    \n    data = preprocess_inputs(X1, X2, y, smote=smote)\n    X1_train, X1_val, X1_test = data['texts']\n    X2_train, X2_val, X2_test = data['images']\n    y_train, y_val, y_test = data['labels']\n\n    checkpoint_IF_path = './model_checkpoint/{}.h5'.format(name.split('-')[0] + '-' + '-'.join(name.split('-')[2:]))\n    history_IF_path = './model_history/{}.npy'.format(name.split('-')[0] + '-' + '-'.join(name.split('-')[2:]))\n\n    if not(os.path.exists(checkpoint_IF_path) and os.path.exists(history_IF_path)):\n        print('Create new IF model:', os.path.split(checkpoint_IF_path)[1])\n\n        model_IF = create_model_IF(X1_train.shape[1:], X2_train.shape[1:], lstm=lstm)\n        checkpoint_IF = ModelCheckpoint(checkpoint_IF_path, save_best_only=True, verbose=verbose)\n        PATIENCE_IF = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=PATIENCE)\n        \n        history_IF = model_IF.fit([X1_train, X2_train], y_train, validation_data=([X1_val, X2_val], y_val), \n                            epochs=EPOCHS, batch_size=batch_size, verbose=verbose,\n                            callbacks=[checkpoint_IF, PATIENCE_IF])\n        if not os.path.exists(os.path.split(history_IF_path)[0]):\n            os.makedirs(os.path.split(history_IF_path)[0])\n        pickle.dump(history_IF.history, open(history_IF_path, 'wb'))\n        \n    model_IF = load_model(checkpoint_IF_path, custom_objects={'SeqSelfAttention': SeqSelfAttention})\n    history_IF = pickle.load(open(history_IF_path, 'rb'))\n    \n    best_epoch = np.argmin(history_IF['val_loss'])\n    print('Model IF checkpoint loaded at epoch:', best_epoch)\n\n    return history_IF, evaluate_model_IF(model_IF, X1_test, X2_test, y_test, verbose=verbose)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:39.008034Z","iopub.execute_input":"2022-08-12T17:37:39.008421Z","iopub.status.idle":"2022-08-12T17:37:39.024067Z","shell.execute_reply.started":"2022-08-12T17:37:39.008386Z","shell.execute_reply":"2022-08-12T17:37:39.023019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_and_evaluate_LF(name, X1, X2, y, verbose=0, lstm=True):\n    \n    if 'multiple' in name:\n        batch_size = BATCH_SIZE_MULTIPLE\n        if DO_SMOTE_MULTIPLE == True:\n            smote = True\n        else:\n            smote = False\n    else:\n        batch_size = BATCH_SIZE_SINGLE # 128\n        if DO_SMOTE_SINGLE == True:\n            smote = True\n        else:\n            smote = False\n\n    data = preprocess_inputs(X1, X2, y, smote=smote)\n    X1_train, X1_val, X1_test = data['texts']\n    X2_train, X2_val, X2_test = data['images']\n    y_train, y_val, y_test = data['labels']\n\n    PATIENCE_text = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=PATIENCE)\n    PATIENCE_image = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=PATIENCE)\n\n    checkpoint_text_path = './model_checkpoint/{}.h5'.format(name.split('-')[0] + '-' + '-'.join(name.split('-')[3:]))\n    checkpoint_image_path = './model_checkpoint/{}.h5'.format(name.split('-')[0] + '-' + name.split('-')[2])\n\n    history_text_path = './model_history/{}.npy'.format(name.split('-')[0] + '-' + '-'.join(name.split('-')[3:]))\n    history_image_path = './model_history/{}.npy'.format(name.split('-')[0] + '-' + name.split('-')[2])\n\n#     if lstm == True:\n#         checkpoint_image_path = './model_checkpoint/{}.h5'.format(name.split('-')[0] + '-' + name.split('-')[2] + '-lstm')\n#         history_image_path = './model_history/{}.npy'.format(name.split('-')[0] + '-' + name.split('-')[2] + '-lstm')\n    \n    if not (os.path.exists(checkpoint_text_path) and os.path.exists(history_text_path)):\n        print('Create new text model:', os.path.split(checkpoint_text_path)[1])\n\n        model_text = create_model_text(X1_train.shape[1:], lstm=lstm)\n        checkpoint_text = ModelCheckpoint(checkpoint_text_path, save_best_only=True, verbose=verbose)\n        history_text = model_text.fit(X1_train, y_train, validation_data=(X1_val, y_val), \n                                  epochs=EPOCHS, batch_size=batch_size, verbose=verbose,\n                                  callbacks=[checkpoint_text, PATIENCE_text])\n        if not os.path.exists(os.path.split(history_text_path)[0]):\n            os.makedirs(os.path.split(history_text_path)[0])\n        pickle.dump(history_text.history, open(history_text_path, 'wb'))\n    \n    if not(os.path.exists(checkpoint_image_path) and os.path.exists(history_image_path)):\n        print('Create new image model:', os.path.split(checkpoint_image_path)[1])\n\n        model_image = create_model_image(X2_train.shape[1:], lstm=lstm)\n        checkpoint_image = ModelCheckpoint(checkpoint_image_path, \n                                       save_best_only=True, verbose=verbose)\n        history_image = model_image.fit(X2_train, y_train, validation_data=(X2_val, y_val), \n                                epochs=EPOCHS, batch_size=batch_size, verbose=verbose,\n                                callbacks=[checkpoint_image, PATIENCE_image])\n        pickle.dump(history_image.history, open(history_image_path, 'wb'))\n    \n    model_text = load_model(checkpoint_text_path)\n    model_image = load_model(checkpoint_image_path)\n\n    history_text = pickle.load(open(history_text_path, 'rb'))    \n    history_image = pickle.load(open(history_image_path, 'rb'))\n\n    y_pred_text = model_text.predict(X1_test)\n    y_pred_image = model_image.predict(X2_test)\n\n    best_epoch_text = np.argmin(history_text['val_loss'])\n    best_epoch_image = np.argmin(history_image['val_loss'])\n    print('Model text checkpoint loaded at epoch:', best_epoch_text)\n    print('Model image checkpoint loaded at epoch:', best_epoch_image)\n    \n    val_acc_text = history_text['val_accuracy'][best_epoch_text]\n    val_acc_image = history_image['val_accuracy'][best_epoch_image]\n    weights = get_average_weights(val_acc_text, val_acc_image)\n    print('Model weights (text, image):', weights)\n\n    y_pred = weighted_average(weights, np.asarray([y_pred_text, y_pred_image], dtype='float32'))\n\n    eval_text = evaluate_model_uni(model_text, X1_test, y_test, verbose=verbose)\n    eval_image = evaluate_model_uni(model_image, X2_test, y_test, verbose=verbose)\n    eval_LF = evaluate_model_LF(y_test, y_pred, verbose=verbose)\n    return eval_text, eval_image, eval_LF","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:39.025963Z","iopub.execute_input":"2022-08-12T17:37:39.026367Z","iopub.status.idle":"2022-08-12T17:37:39.051412Z","shell.execute_reply.started":"2022-08-12T17:37:39.026323Z","shell.execute_reply":"2022-08-12T17:37:39.050236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_and_evaluate_HF(name, X1, X2, y, verbose=0, lstm=True):\n\n    if 'multiple' in name:\n        batch_size = BATCH_SIZE_MULTIPLE\n        if DO_SMOTE_MULTIPLE == True:\n            smote = True\n        else:\n            smote = False\n    else:\n        batch_size = BATCH_SIZE_SINGLE # 128\n        if DO_SMOTE_SINGLE == True:\n            smote = True\n        else:\n            smote = False\n\n    data = preprocess_inputs(X1, X2, y, smote=smote)\n    X1_train, X1_val, X1_test = data['texts']\n    X2_train, X2_val, X2_test = data['images']\n    y_train, y_val, y_test = data['labels']\n\n    PATIENCE_text = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=PATIENCE)\n    PATIENCE_image = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=PATIENCE)\n    PATIENCE_IF = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=PATIENCE)\n\n    checkpoint_text_path = './model_checkpoint/{}.h5'.format(name.split('-')[0] + '-' + '-'.join(name.split('-')[3:]))\n    checkpoint_image_path = './model_checkpoint/{}.h5'.format(name.split('-')[0] + '-' + name.split('-')[2])\n    checkpoint_IF_path = './model_checkpoint/{}.h5'.format(name.split('-')[0] + '-' + '-'.join(name.split('-')[2:]))\n\n    history_text_path = './model_history/{}.npy'.format(name.split('-')[0] + '-' + '-'.join(name.split('-')[3:]))\n    history_image_path = './model_history/{}.npy'.format(name.split('-')[0] + '-' + name.split('-')[2])\n    history_IF_path = './model_history/{}.npy'.format(name.split('-')[0] + '-' + '-'.join(name.split('-')[2:]))\n\n#     if lstm == True:\n#         checkpoint_image_path = './model_checkpoint/{}.h5'.format(name.split('-')[0] + '-' + name.split('-')[2] + '-lstm')\n#         history_image_path = './model_history/{}.npy'.format(name.split('-')[0] + '-' + name.split('-')[2] + '-lstm')\n\n    if not(os.path.exists(checkpoint_text_path) and os.path.exists(history_text_path)):\n        print('Create new text model:', os.path.split(checkpoint_text_path)[1])\n\n        model_text = create_model_text(X1_train.shape[1:], lstm=lstm)\n        checkpoint_text = ModelCheckpoint(checkpoint_text_path, save_best_only=True, verbose=verbose)\n        history_text = model_text.fit(X1_train, y_train, validation_data=(X1_val, y_val), \n                                  epochs=EPOCHS, batch_size=batch_size, verbose=verbose,\n                                  callbacks=[checkpoint_text, PATIENCE_text])\n        if not os.path.exists(os.path.split(history_text_path)[0]):\n            os.makedirs(os.path.split(history_text_path)[0])\n        pickle.dump(history_text.history, open(history_text_path, 'wb'))\n\n    if not(os.path.exists(checkpoint_image_path) and os.path.exists(history_image_path)):\n        print('Create new image model:', os.path.split(checkpoint_image_path)[1])\n\n        model_image = create_model_image(X2_train.shape[1:], lstm=lstm)        \n        checkpoint_image = ModelCheckpoint(checkpoint_image_path, save_best_only=True, verbose=verbose)\n        history_image = model_image.fit(X2_train, y_train, validation_data=(X2_val, y_val), \n                                epochs=EPOCHS, batch_size=batch_size, verbose=verbose,\n                                callbacks=[checkpoint_image, PATIENCE_image])\n        pickle.dump(history_image.history, open(history_image_path, 'wb'))\n    \n    if not(os.path.exists(checkpoint_IF_path) and os.path.exists(history_IF_path)):\n        print('Create new IF model:', os.path.split(checkpoint_IF_path)[1])\n\n        model_IF = create_model_IF(X1_train.shape[1:], X2_train.shape[1:], lstm=lstm)\n        checkpoint_IF = ModelCheckpoint(checkpoint_IF_path, save_best_only=True, verbose=verbose)\n        history_IF = model_IF.fit([X1_train, X2_train], y_train, validation_data=([X1_val, X2_val], y_val), \n                            epochs=EPOCHS, batch_size=batch_size, verbose=verbose,\n                            callbacks=[checkpoint_IF, PATIENCE_IF])\n        pickle.dump(history_IF.history, open(history_IF_path, 'wb'))\n\n    model_text = load_model(checkpoint_text_path)\n    model_image = load_model(checkpoint_image_path)\n    model_IF = load_model(checkpoint_IF_path, custom_objects={'SeqSelfAttention': SeqSelfAttention})\n\n    history_image = pickle.load(open(history_image_path, 'rb'))\n    history_text = pickle.load(open(history_text_path, 'rb'))\n    history_IF = pickle.load(open(history_IF_path, 'rb'))\n\n    y_pred_text = model_text.predict(X1_test)\n    y_pred_image = model_image.predict(X2_test)\n    y_pred_IF = model_IF.predict([X1_test, X2_test])\n    \n    best_epoch_text = np.argmin(history_text['val_loss'])\n    best_epoch_image = np.argmin(history_image['val_loss'])\n    best_epoch_IF = np.argmin(history_IF['val_loss'])\n    print('Model text checkpoint loaded at epoch:', best_epoch_text)\n    print('Model image checkpoint loaded at epoch:', best_epoch_image)\n    print('Model IF checkpoint loaded at epoch:', best_epoch_IF)\n\n    val_acc_text = history_text['val_accuracy'][best_epoch_text]\n    val_acc_image = history_image['val_accuracy'][best_epoch_image]\n    val_acc_IF = history_IF['val_accuracy'][best_epoch_IF]\n    \n    weights = get_average_weights(val_acc_text, val_acc_image, val_acc_IF)\n    print('Model weights (text, image, IF):', weights)\n    y_pred = weighted_average(weights, np.asarray([y_pred_text, y_pred_image, y_pred_IF], dtype='float32'))\n\n    eval_text = evaluate_model_uni(model_text, X1_test, y_test, verbose=verbose)\n    eval_image = evaluate_model_uni(model_image, X2_test, y_test, verbose=verbose)\n    eval_IF = evaluate_model_IF(model_IF, X1_test, X2_test, y_test, verbose=verbose)\n    eval_HF = evaluate_model_LF(y_test, y_pred, verbose=verbose)\n    return eval_text, eval_image, eval_IF, eval_HF","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:39.053257Z","iopub.execute_input":"2022-08-12T17:37:39.053662Z","iopub.status.idle":"2022-08-12T17:37:39.086145Z","shell.execute_reply.started":"2022-08-12T17:37:39.053624Z","shell.execute_reply":"2022-08-12T17:37:39.085114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model_IF(model, X_texts, X_images, y_test, verbose=1):\n\n    loss, acc, f1_macro, f1_weighted = model.evaluate([X_texts, X_images], y_test, verbose=verbose)\n\n    if verbose == 1:\n        print('Loss:', loss)\n        print('Accuracy:', acc)\n        print('Macro F1-score:', f1_macro)\n        print('Weighted F1-score:', f1_weighted)\n\n        y_pred = model.predict([X_texts, X_images])\n        matrix = confusion_matrix(le.inverse_transform(y_test.argmax(axis=1)), le.inverse_transform(y_pred.argmax(axis=1)), \n                                  labels=list(le.classes_))\n        cm_disp = ConfusionMatrixDisplay(confusion_matrix=matrix,\n                                  display_labels=list(le.classes_))\n        cm_disp.plot()\n        plt.show()\n        \n    return acc, f1_macro, f1_weighted\n\ndef evaluate_model_LF(y_true, y_pred, verbose=0):\n    \n    y_pred = le.inverse_transform(y_pred.argmax(axis=1))\n    y_true = le.inverse_transform(y_true.argmax(axis=1))\n\n    acc = accuracy_score(y_true, y_pred)\n    f1_macro = f1_score(y_true, y_pred, average='macro')\n    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n\n    if verbose == 1:\n        print(classification_report(y_true, y_pred))\n        matrix = confusion_matrix(y_true, y_pred,\n                                  labels=list(le.classes_))\n        cm_disp = ConfusionMatrixDisplay(confusion_matrix=matrix,\n                                  display_labels=list(le.classes_))\n        cm_disp.plot()\n        plt.show()\n\n    return acc, f1_macro, f1_weighted\n\ndef evaluate_model_uni(model, X_test, y_test, verbose=1):\n    \n    loss, acc, f1_macro, f1_weighted = model.evaluate(X_test, y_test, verbose=verbose)\n    \n    if verbose == 1:\n        print('Loss:', loss)\n        print('Accuracy:', acc)\n        print('Macro F1-score:', f1_macro)\n        print('Weighted F1-score:', f1_weighted)\n        \n    return acc, f1_macro, f1_weighted","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:39.088959Z","iopub.execute_input":"2022-08-12T17:37:39.089315Z","iopub.status.idle":"2022-08-12T17:37:39.103453Z","shell.execute_reply.started":"2022-08-12T17:37:39.089279Z","shell.execute_reply":"2022-08-12T17:37:39.102253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history):\n    fig = plt.figure(figsize=(20, 5))\n\n    fig.add_subplot(1, 4, 1)\n    plt.plot(history['loss'])\n    plt.plot(history['val_loss'])\n    plt.title('LOSS')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='best')\n\n    fig.add_subplot(1, 4, 2)\n    plt.plot(history['accuracy'])\n    plt.plot(history['val_accuracy'])\n    plt.title('ACCURACY')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='best')\n\n    fig.add_subplot(1, 4, 3)\n    plt.plot(history['f1_macro'])\n    plt.plot(history['val_f1_macro'])\n    plt.title('Macro F1-SCORE')\n    plt.ylabel('f1-macro')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='best')\n\n    fig.add_subplot(1, 4, 4)\n    plt.plot(history['f1_weighted'])\n    plt.plot(history['val_f1_weighted'])\n    plt.title('Weighted F1-SCORE')\n    plt.ylabel('f1-weighted')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='best')\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:39.104982Z","iopub.execute_input":"2022-08-12T17:37:39.105901Z","iopub.status.idle":"2022-08-12T17:37:39.119366Z","shell.execute_reply.started":"2022-08-12T17:37:39.10586Z","shell.execute_reply":"2022-08-12T17:37:39.118402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def style_dataframe(dataframe):\n    return dataframe.style.highlight_max(subset=['Accuracy', 'F1-macro', 'F1-weighted'], props='color:lawngreen', axis=0)\\\n                          .highlight_min(subset=['Accuracy', 'F1-macro', 'F1-weighted'], props='color:tomato', axis=0)\n\ndef highlight_neg(cell):\n    if type(cell) != str and cell < 0 :\n        return 'color: tomato'\n    else:\n        return 'color: lawngreen'\n\ndef display_dataframes(dfs, names=[], index=False):\n    def to_df(x):\n        if isinstance(x, pd.Series):\n            return pd.DataFrame(x)\n        else:\n            return x\n    html_str = ''\n    if names:\n        html_str += ('<tr>' + \n                     ''.join(f'<td style=\"text-align:center\">{name}</td>' for name in names) + \n                     '</tr>')\n    html_str += ('<tr>' + \n                 ''.join(f'<td style=\"vertical-align:top\"> {to_df(df).to_html()}</td>' \n                         for df in dfs) + \n                 '</tr>')\n    html_str = f'<table>{html_str}</table>'\n    html_str = html_str.replace('table','table style=\"display:inline\"')\n    display_html(html_str, raw=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:39.121473Z","iopub.execute_input":"2022-08-12T17:37:39.122374Z","iopub.status.idle":"2022-08-12T17:37:39.13352Z","shell.execute_reply.started":"2022-08-12T17:37:39.122313Z","shell.execute_reply":"2022-08-12T17:37:39.132534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"mvsa_single_multimodal_labels, _, _ = load_labels('../input/mvsa-features/labels/mvsa-single-labels.hdf5')\nmvsa_multiple_multimodal_labels, _, _ = load_labels('../input/mvsa-features/labels/mvsa-multiple-labels.hdf5')\n\nle = LabelEncoder()\nle.fit(mvsa_multiple_multimodal_labels)\nNUM_CLASSES = len(le.classes_) # = 3\nmapping = dict(zip(range(len(le.classes_)), le.classes_))\nprint(mapping)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:39.135243Z","iopub.execute_input":"2022-08-12T17:37:39.13667Z","iopub.status.idle":"2022-08-12T17:37:39.303836Z","shell.execute_reply.started":"2022-08-12T17:37:39.136617Z","shell.execute_reply":"2022-08-12T17:37:39.302422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names = ['resnet101-bert', 'resnet101-bert-lstm', 'densenet201-bert-lstm', 'densenet201-bert-pos-lstm', \n#                  'densenet201-bert-ner-lstm', \n                 'densenet201-bert-pos-ner-lstm']\nvisual_feature_names = process_dup([name.split('-')[0] for name in feature_names])\ntextual_feature_names = process_dup(['-'.join(name.split('-')[1:]) for name in feature_names])\n# for i in range(len(feature_names)):\n#     x = ' '.join(feature_names[i].split('-')[1:]).rstrip()\n#     if len(x.split()) > 1:\n#         x = '-'.join(x.rstrip('-lstm').rstrip().split())\n#     textual_feature_names.append(x)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:39.306086Z","iopub.execute_input":"2022-08-12T17:37:39.307041Z","iopub.status.idle":"2022-08-12T17:37:39.314772Z","shell.execute_reply.started":"2022-08-12T17:37:39.306983Z","shell.execute_reply":"2022-08-12T17:37:39.31375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mvsa_single_features, mvsa_multiple_features = get_features(feature_names)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:39.316771Z","iopub.execute_input":"2022-08-12T17:37:39.317664Z","iopub.status.idle":"2022-08-12T17:37:45.362512Z","shell.execute_reply.started":"2022-08-12T17:37:39.317613Z","shell.execute_reply":"2022-08-12T17:37:45.361454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fix random indices for consistency between other experiments\nmvsa_single_features, mvsa_single_multimodal_labels = shuffle_mvsa(mvsa_single_features, mvsa_single_multimodal_labels, np.load('../input/mvsa-shuffle-indices/mvsa-single-shuffle-indices.npy'))\nmvsa_multiple_features, mvsa_multiple_multimodal_labels = shuffle_mvsa(mvsa_multiple_features, mvsa_multiple_multimodal_labels, np.load('../input/mvsa-shuffle-indices/mvsa-multiple-shuffle-indices.npy'))","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:45.364051Z","iopub.execute_input":"2022-08-12T17:37:45.365098Z","iopub.status.idle":"2022-08-12T17:37:46.284236Z","shell.execute_reply.started":"2022-08-12T17:37:45.365052Z","shell.execute_reply":"2022-08-12T17:37:46.282836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reset_seeds()\nEPOCHS = 100\nVALIDATION_SPLIT = 0.1\nPATIENCE = 10\nVERBOSE = 1\n\nBATCH_SIZE_SINGLE = 128\nBATCH_SIZE_MULTIPLE = 256\n\nDO_SMOTE_SINGLE = True\nDO_SMOTE_MULTIPLE = True\n\nNUM_LSTM = 256\nDROPOUT_INPUT = 0.0\nDROPOUT_LSTM = 0.0\n\n# NUM_LSTM_IMG = 256\nDROPOUT_INPUT_IMG = 0.0\n# DROPOUT_LSTM_IMG = 0.0\n\nDROPOUT_ATT = 0.0\nOPTIMIZER = 'adam'\nLOSS = 'categorical_crossentropy'#tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T17:37:46.285871Z","iopub.execute_input":"2022-08-12T17:37:46.286269Z","iopub.status.idle":"2022-08-12T17:37:46.294696Z","shell.execute_reply.started":"2022-08-12T17:37:46.286232Z","shell.execute_reply":"2022-08-12T17:37:46.293405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Intermediate Fusion","metadata":{}},{"cell_type":"code","source":"print('MVSA-Single with Intermediate Fusion')\nscores = []\nfor i in range(len(feature_names)):\n    print('MVSA-Single:', feature_names[i])\n    if 'lstm' in feature_names[i]:\n        _, score = run_and_evaluate_IF('single-IF-' + feature_names[i], \n                                       mvsa_single_features[i][0],\n                                       mvsa_single_features[i][1],\n                                       mvsa_single_multimodal_labels, \n                                       verbose=VERBOSE, lstm=True)\n    else:\n        _, score = run_and_evaluate_IF('single-IF-' + feature_names[i], \n                                       mvsa_single_features[i][0],\n                                       mvsa_single_features[i][1],\n                                       mvsa_single_multimodal_labels, \n                                       verbose=VERBOSE, lstm=False)\n    scores.append(score)\n    print()\ndf0_single_scores_IF = pd.DataFrame(scores, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)\n\nprint('----------------------------------------')\nprint('\\nMVSA-Multiple with Intermediate Fusion')\nscores = []\nfor i in range(len(feature_names)):\n    print('MVSA-Multiple:', feature_names[i])\n    if 'lstm' in feature_names[i]:\n        _, score = run_and_evaluate_IF('multiple-IF-' + feature_names[i], \n                                       mvsa_multiple_features[i][0],\n                                       mvsa_multiple_features[i][1],\n                                       mvsa_multiple_multimodal_labels, \n                                       verbose=VERBOSE, lstm=True)\n    else:\n        _, score = run_and_evaluate_IF('multiple-IF-' + feature_names[i], \n                                       mvsa_multiple_features[i][0],\n                                       mvsa_multiple_features[i][1],\n                                       mvsa_multiple_multimodal_labels, \n                                       verbose=VERBOSE, lstm=False)\n    scores.append(score)\n    print()\ndf0_multiple_scores_IF = pd.DataFrame(scores, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:28:48.094822Z","iopub.execute_input":"2022-08-04T04:28:48.095141Z","iopub.status.idle":"2022-08-04T04:30:43.540894Z","shell.execute_reply.started":"2022-08-04T04:28:48.095112Z","shell.execute_reply":"2022-08-04T04:30:43.539475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Late Fusion","metadata":{}},{"cell_type":"code","source":"print('MVSA-Single with Late Fusion')\nscores_text = []\nscores_image = []\nscores_LF = []\nfor i in range(len(feature_names)):\n    print('MVSA-Single:', feature_names[i])\n    if 'lstm' in feature_names[i]:\n        score_text, score_image, score_LF = run_and_evaluate_LF('single-LF-' + feature_names[i],\n                                                                mvsa_single_features[i][0], \n                                                                mvsa_single_features[i][1],\n                                                                mvsa_single_multimodal_labels, \n                                                                verbose=VERBOSE, lstm=True)\n    else:\n        score_text, score_image, score_LF = run_and_evaluate_LF('single-LF-' + feature_names[i],\n                                                                mvsa_single_features[i][0], \n                                                                mvsa_single_features[i][1],\n                                                                mvsa_single_multimodal_labels, \n                                                                verbose=VERBOSE, lstm=False)    \n    scores_text.append(score_text)\n    scores_image.append(score_image)\n    scores_LF.append(score_LF)\n    print()\n\ndf1_single_scores_text = pd.DataFrame(scores_text, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=textual_feature_names)\ndf1_single_scores_image = pd.DataFrame(scores_image, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=visual_feature_names)\ndf1_single_scores_LF = pd.DataFrame(scores_LF, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)\n\nprint('--------------------------------')\nprint('\\nMVSA-Multiple with Late Fusion')\nscores_text = []\nscores_image = []\nscores_LF = []\nfor i in range(len(feature_names)):\n    print('MVSA-Multiple:', feature_names[i])\n    if 'lstm' in feature_names[i]:\n        score_text, score_image, score_LF = run_and_evaluate_LF('multiple-LF-' + feature_names[i],\n                                                                mvsa_multiple_features[i][0], \n                                                                mvsa_multiple_features[i][1],\n                                                                mvsa_multiple_multimodal_labels, \n                                                                verbose=VERBOSE, lstm=True)\n    else:\n        score_text, score_image, score_LF = run_and_evaluate_LF('multiple-LF-' + feature_names[i],\n                                                                mvsa_multiple_features[i][0], \n                                                                mvsa_multiple_features[i][1],\n                                                                mvsa_multiple_multimodal_labels, \n                                                                verbose=VERBOSE, lstm=False)\n    scores_text.append(score_text)\n    scores_image.append(score_image)\n    scores_LF.append(score_LF)\n    print()\n\ndf1_multiple_scores_text = pd.DataFrame(scores_text, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=textual_feature_names)\ndf1_multiple_scores_image = pd.DataFrame(scores_image, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=visual_feature_names)\ndf1_multiple_scores_LF = pd.DataFrame(scores_LF, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:30:43.544487Z","iopub.execute_input":"2022-08-04T04:30:43.544952Z","iopub.status.idle":"2022-08-04T04:32:00.889798Z","shell.execute_reply.started":"2022-08-04T04:30:43.544919Z","shell.execute_reply":"2022-08-04T04:32:00.888782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hybrid Fusion","metadata":{}},{"cell_type":"code","source":"print('MVSA-Single with Hybrid Fusion')\nscores_text = []\nscores_image = []\nscores_IF = []\nscores_HF = []\nfor i in range(len(feature_names)):\n    print('MVSA-Single:', feature_names[i])\n    if 'lstm' in feature_names[i]:\n        score_text, score_image, score_IF, score_HF = run_and_evaluate_HF('single-HF-' + feature_names[i], \n                                                                          mvsa_single_features[i][0], \n                                                                          mvsa_single_features[i][1], \n                                                                          mvsa_single_multimodal_labels, \n                                                                          verbose=VERBOSE, lstm=True)\n    else:\n        score_text, score_image, score_IF, score_HF = run_and_evaluate_HF('single-HF-' + feature_names[i], \n                                                                          mvsa_single_features[i][0], \n                                                                          mvsa_single_features[i][1], \n                                                                          mvsa_single_multimodal_labels, \n                                                                          verbose=VERBOSE, lstm=False)\n    scores_text.append(score_text)\n    scores_image.append(score_image)\n    scores_IF.append(score_IF)\n    scores_HF.append(score_HF)\n    print()\n\ndf2_single_scores_text = pd.DataFrame(scores_text, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=textual_feature_names)\ndf2_single_scores_image = pd.DataFrame(scores_image, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=visual_feature_names)\ndf2_single_scores_IF = pd.DataFrame(scores_IF, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)\ndf2_single_scores_HF = pd.DataFrame(scores_HF, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)\n\nprint('----------------------------------')\nprint('\\nMVSA-Multiple with Hybrid Fusion')\nscores_text = []\nscores_image = []\nscores_IF = []\nscores_HF = []\nfor i in range(len(feature_names)):\n    print('MVSA-Multiple:', feature_names[i])\n    if 'lstm' in feature_names[i]:\n        score_text, score_image, score_IF, score_HF = run_and_evaluate_HF('multiple-HF-' + feature_names[i], \n                                                                          mvsa_multiple_features[i][0], \n                                                                          mvsa_multiple_features[i][1], \n                                                                          mvsa_multiple_multimodal_labels, \n                                                                          verbose=VERBOSE, lstm=True)\n    else:\n        score_text, score_image, score_IF, score_HF = run_and_evaluate_HF('multiple-HF-' + feature_names[i], \n                                                                          mvsa_multiple_features[i][0], \n                                                                          mvsa_multiple_features[i][1], \n                                                                          mvsa_multiple_multimodal_labels, \n                                                                          verbose=VERBOSE, lstm=False)\n    scores_text.append(score_text)\n    scores_image.append(score_image)\n    scores_IF.append(score_IF)\n    scores_HF.append(score_HF)\n    print()\n\ndf2_multiple_scores_text = pd.DataFrame(scores_text, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=textual_feature_names)\ndf2_multiple_scores_image = pd.DataFrame(scores_image, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=visual_feature_names)\ndf2_multiple_scores_IF = pd.DataFrame(scores_IF, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)\ndf2_multiple_scores_HF = pd.DataFrame(scores_HF, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:32:00.891831Z","iopub.execute_input":"2022-08-04T04:32:00.892313Z","iopub.status.idle":"2022-08-04T04:33:19.680471Z","shell.execute_reply.started":"2022-08-04T04:32:00.892255Z","shell.execute_reply":"2022-08-04T04:33:19.679402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display results","metadata":{}},{"cell_type":"code","source":"print('Intermediate Fusion')\ndisplay_dataframes((style_dataframe(df0_single_scores_IF), style_dataframe(df0_multiple_scores_IF)), \n                   names=['MVSA-Single', 'MVSA-Multiple'])","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:19.682339Z","iopub.execute_input":"2022-08-04T04:33:19.683595Z","iopub.status.idle":"2022-08-04T04:33:19.791145Z","shell.execute_reply.started":"2022-08-04T04:33:19.683546Z","shell.execute_reply":"2022-08-04T04:33:19.790006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('LATE FUSION \\n')\nprint('MVSA-Single')\nprint(display_dataframes((style_dataframe(df1_single_scores_text), style_dataframe(df1_single_scores_image), \n                          style_dataframe(df1_single_scores_LF)), \n                         names=['Model Text', 'Model Image', 'Model LF']))\nprint('\\nMVSA-Multiple')\nprint(display_dataframes((style_dataframe(df1_multiple_scores_text), style_dataframe(df1_multiple_scores_image), style_dataframe(df1_multiple_scores_LF)), \n                   names=['Model Text', 'Model Image', 'Model LF']))","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:19.792383Z","iopub.execute_input":"2022-08-04T04:33:19.792766Z","iopub.status.idle":"2022-08-04T04:33:19.873211Z","shell.execute_reply.started":"2022-08-04T04:33:19.792696Z","shell.execute_reply":"2022-08-04T04:33:19.871939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('HYBRID FUSION \\n')\nprint('MVSA-Single')\nprint(display_dataframes((style_dataframe(df2_single_scores_text), style_dataframe(df2_single_scores_image), \n                          style_dataframe(df2_single_scores_IF), style_dataframe(df2_single_scores_HF)), \n                   names=['Model Text', 'Model Image', 'Model IF', 'Model HF']))\nprint('\\nMVSA-Multiple')\nprint(display_dataframes((style_dataframe(df2_multiple_scores_text), style_dataframe(df2_multiple_scores_image), \n                          style_dataframe(df2_multiple_scores_IF), style_dataframe(df2_multiple_scores_HF)), \n                   names=['Model Text', 'Model Image', 'Model IF', 'Model HF']))","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:19.874835Z","iopub.execute_input":"2022-08-04T04:33:19.875598Z","iopub.status.idle":"2022-08-04T04:33:19.980937Z","shell.execute_reply.started":"2022-08-04T04:33:19.87555Z","shell.execute_reply":"2022-08-04T04:33:19.979755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get max values of late and intermediate fusion\ndf_single_higher_fusion = pd.DataFrame(np.where(df1_single_scores_LF.gt(df0_single_scores_IF.values), \n                                                df1_single_scores_LF.values, df0_single_scores_IF.values),\n                                       columns=['Accuracy','F1-macro','F1-weighted'], index=feature_names)\n\ndf_multiple_higher_fusion = pd.DataFrame(np.where(df1_multiple_scores_LF.gt(df0_multiple_scores_IF.values),\n                                                  df1_multiple_scores_LF.values, df0_multiple_scores_IF.values),\n                                         columns=['Accuracy','F1-macro','F1-weighted'], index=feature_names)\n\ndf_single_subtract = df2_single_scores_HF.subtract(df_single_higher_fusion)\ndf_multiple_subtract = df2_multiple_scores_HF.subtract(df_multiple_higher_fusion)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:19.982801Z","iopub.execute_input":"2022-08-04T04:33:19.983125Z","iopub.status.idle":"2022-08-04T04:33:19.992604Z","shell.execute_reply.started":"2022-08-04T04:33:19.983096Z","shell.execute_reply":"2022-08-04T04:33:19.991345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Compare Hybrid Fusion with other Fusion Models (>scores)')\ndisplay_dataframes((df_single_subtract.style.applymap(highlight_neg), df_multiple_subtract.style.applymap(highlight_neg)), \n                   names=['MVSA-Single', 'MVSA-Multiple'])","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:20.000451Z","iopub.execute_input":"2022-08-04T04:33:20.001006Z","iopub.status.idle":"2022-08-04T04:33:20.024451Z","shell.execute_reply.started":"2022-08-04T04:33:20.000965Z","shell.execute_reply":"2022-08-04T04:33:20.022808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drafts","metadata":{}},{"cell_type":"code","source":"# import shutil\n# def remove_folder(path):\n#     # check if folder exists\n#     if os.path.exists(path):\n#          # remove if exists\n#          shutil.rmtree(path)\n#     else:\n#          # throw your exception to handle this special scenario\n#          raise XXError(\"your exception\") \n# remove_folder(\"./model_checkpoint\")\n# remove_folder(\"./model_history\")","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:20.02627Z","iopub.execute_input":"2022-08-04T04:33:20.027455Z","iopub.status.idle":"2022-08-04T04:33:20.032584Z","shell.execute_reply.started":"2022-08-04T04:33:20.027407Z","shell.execute_reply":"2022-08-04T04:33:20.031648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## Choose best\n# # Load text feature\n# mvsa_single_bert, mvsa_multiple_bert = load_mvsa_feature('bert-base')\n# mvsa_single_pos_bow, mvsa_multiple_pos_bow = load_mvsa_feature('pos-bow')\n# mvsa_single_pos_tfidf, mvsa_multiple_pos_tfidf = load_mvsa_feature('pos-tfidf')\n# mvsa_single_ner_bow, mvsa_multiple_ner_bow = load_mvsa_feature('ner-bow')\n# mvsa_single_ner_tfidf, mvsa_multiple_ner_tfidf = load_mvsa_feature('ner-tfidf')\n\n# ## Load image feature\n# mvsa_single_vgg16, mvsa_multiple_vgg16 = load_mvsa_feature('vgg16')\n# mvsa_single_vgg19, mvsa_multiple_vgg19 = load_mvsa_feature('vgg19')\n# mvsa_single_resnet50, mvsa_multiple_resnet50 = load_mvsa_feature('resnet50')\n# mvsa_single_resnet101, mvsa_multiple_resnet101 = load_mvsa_feature('resnet101')\n# mvsa_single_resnet152, mvsa_multiple_resnet152 = load_mvsa_feature('resnet152')\n# mvsa_single_densenet121, mvsa_multiple_densenet121 = load_mvsa_feature('densenet121')\n# mvsa_single_densenet169, mvsa_multiple_densenet169 = load_mvsa_feature('densenet169')\n# mvsa_single_densenet201, mvsa_multiple_densenet201 = load_mvsa_feature('densenet201')\n\n# mvsa_single_bert_pos = np.concatenate((mvsa_single_bert, mvsa_single_pos_tfidf), axis=1)\n# mvsa_single_bert_ner = np.concatenate((mvsa_single_bert, mvsa_single_ner_tfidf), axis=1)\n# mvsa_single_bert_pos_ner = np.concatenate((mvsa_single_bert, mvsa_single_pos_tfidf, mvsa_single_ner_tfidf), axis=1)\n\n# mvsa_multiple_bert_pos = np.concatenate((mvsa_multiple_bert, mvsa_multiple_pos_tfidf), axis=1)\n# mvsa_multiple_bert_ner = np.concatenate((mvsa_multiple_bert, mvsa_multiple_ner_tfidf), axis=1)\n# mvsa_multiple_bert_pos_ner = np.concatenate((mvsa_multiple_bert, mvsa_multiple_pos_tfidf, mvsa_multiple_ner_tfidf), axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:20.034118Z","iopub.execute_input":"2022-08-04T04:33:20.035322Z","iopub.status.idle":"2022-08-04T04:33:20.04416Z","shell.execute_reply.started":"2022-08-04T04:33:20.035277Z","shell.execute_reply":"2022-08-04T04:33:20.042954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mvsa_single_features_split = get_preprocess_input(feature_names, mvsa_single_features, mvsa_single_multimodal_labels)\n# mvsa_multiple_features_split = get_preprocess_input(feature_names, mvsa_multiple_features, mvsa_multiple_multimodal_labels)\n# mvsa_single_features, mvsa_single_multimodal_labels = shuffle_mvsa(mvsa_single_features, mvsa_single_multimodal_labels)\n# mvsa_multiple_features, mvsa_multiple_multimodal_labels = shuffle_mvsa(mvsa_multiple_features, mvsa_multiple_multimodal_labels)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:20.046397Z","iopub.execute_input":"2022-08-04T04:33:20.046762Z","iopub.status.idle":"2022-08-04T04:33:20.059572Z","shell.execute_reply.started":"2022-08-04T04:33:20.04673Z","shell.execute_reply":"2022-08-04T04:33:20.058337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # save shuffle indices for other experiments consistency (temporary fix)\n# random_idx_single = np.random.permutation(len(mvsa_single_multimodal_labels))\n# random_idx_multiple = np.random.permutation(len(mvsa_multiple_multimodal_labels))\n# np.save('mvsa-single-shuffle-indices.npy', random_idx_single)\n# np.save('mvsa-multiple-shuffle-indices.npy', random_idx_multiple)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:20.061462Z","iopub.execute_input":"2022-08-04T04:33:20.062332Z","iopub.status.idle":"2022-08-04T04:33:20.072737Z","shell.execute_reply.started":"2022-08-04T04:33:20.062286Z","shell.execute_reply":"2022-08-04T04:33:20.071818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plots","metadata":{}},{"cell_type":"code","source":"if not os.path.exists('./tables'):\n    os.makedirs('./tables')\n\ndef style_dataframe_out(dataframe):\n    return dataframe.style.highlight_max(subset=['Accuracy', 'F1-weighted'], props='color:lawngreen', axis=0)\\\n                          .highlight_min(subset=['Accuracy', 'F1-weighted'], props='color:tomato', axis=0)\n\ndrop_columns = ['F1-macro']\ndef dataframe_to_display(df):\n    return style_dataframe_out(np.round(df, 3).drop(columns=drop_columns))","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:20.074605Z","iopub.execute_input":"2022-08-04T04:33:20.075445Z","iopub.status.idle":"2022-08-04T04:33:20.085254Z","shell.execute_reply.started":"2022-08-04T04:33:20.075399Z","shell.execute_reply":"2022-08-04T04:33:20.084002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"open('./tables/single-IF-scores.html', 'w').write(dataframe_to_display(df0_single_scores_IF).to_html())\nopen('./tables/single-LF-scores.html', 'w').write(dataframe_to_display(df1_single_scores_LF).to_html())\nopen('./tables/single-HF-scores.html', 'w').write(dataframe_to_display(df2_single_scores_HF).to_html())\n\nopen('./tables/multiple-IF-scores.html', 'w').write(dataframe_to_display(df0_multiple_scores_IF).to_html())\nopen('./tables/multiple-LF-scores.html', 'w').write(dataframe_to_display(df1_multiple_scores_LF).to_html())\nopen('./tables/multiple-HF-scores.html', 'w').write(dataframe_to_display(df2_multiple_scores_HF).to_html())","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:20.086608Z","iopub.execute_input":"2022-08-04T04:33:20.087359Z","iopub.status.idle":"2022-08-04T04:33:20.161084Z","shell.execute_reply.started":"2022-08-04T04:33:20.087324Z","shell.execute_reply":"2022-08-04T04:33:20.159748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import plotly.graph_objects as go\n# from plotly.offline import init_notebook_mode, iplot\n# init_notebook_mode(connected=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:20.162578Z","iopub.execute_input":"2022-08-04T04:33:20.163268Z","iopub.status.idle":"2022-08-04T04:33:20.168038Z","shell.execute_reply.started":"2022-08-04T04:33:20.163224Z","shell.execute_reply":"2022-08-04T04:33:20.167158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\n\nWIDTH = 650\nHEIGHT = 400\n\nif not os.path.exists('./plots'):\n    os.makedirs('./plots')","metadata":{"execution":{"iopub.status.busy":"2022-08-12T18:11:39.34748Z","iopub.execute_input":"2022-08-12T18:11:39.347924Z","iopub.status.idle":"2022-08-12T18:11:40.60317Z","shell.execute_reply.started":"2022-08-12T18:11:39.347888Z","shell.execute_reply":"2022-08-12T18:11:40.601923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Num of labels statistics","metadata":{}},{"cell_type":"code","source":"len_single_pos = len([x for x in mvsa_single_multimodal_labels if x == 'positive'])\nlen_single_neu = len([x for x in mvsa_single_multimodal_labels if x == 'neutral'])\nlen_single_neg = len([x for x in mvsa_single_multimodal_labels if x == 'negative'])\n\nlen_multiple_pos = len([x for x in mvsa_multiple_multimodal_labels if x == 'positive'])\nlen_multiple_neu = len([x for x in mvsa_multiple_multimodal_labels if x == 'neutral'])\nlen_multiple_neg = len([x for x in mvsa_multiple_multimodal_labels if x == 'negative'])","metadata":{"execution":{"iopub.status.busy":"2022-08-12T18:07:46.177572Z","iopub.execute_input":"2022-08-12T18:07:46.178821Z","iopub.status.idle":"2022-08-12T18:07:46.207145Z","shell.execute_reply.started":"2022-08-12T18:07:46.178768Z","shell.execute_reply":"2022-08-12T18:07:46.206123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_single_labels = [len_single_pos, len_single_neu, len_single_neg]\nlen_single_labels = pd.DataFrame(len_single_labels, columns=['samples'])\nlen_single_labels['Nhãn'] = ['Tích cực', 'Tiêu cực', 'Trung lập']\nlen_single_labels\n\nfig = px.pie(len_single_labels, values='samples', names='Nhãn', title='Số lượng dữ liệu của từng nhãn MVSA-Single')\nfig.update_layout(margin_b=25, margin_t=50, margin_l=25, margin_r=25, width=WIDTH, height=HEIGHT)\nfig.update_layout(legend_title='Tập dữ liệu')\nfig.write_html('./plots/single-label-plot.html')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T18:25:22.282977Z","iopub.execute_input":"2022-08-12T18:25:22.283496Z","iopub.status.idle":"2022-08-12T18:25:22.367315Z","shell.execute_reply.started":"2022-08-12T18:25:22.283454Z","shell.execute_reply":"2022-08-12T18:25:22.366002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Num label samples pie plots","metadata":{}},{"cell_type":"code","source":"x = preprocess_inputs(mvsa_single_features[0][0], mvsa_single_features[0][1], mvsa_single_multimodal_labels, smote=True)['texts']\nlen_train_single = x[0].shape[0]\nlen_val_single = x[1].shape[0]\nlen_test_single = x[2].shape[0]\nlen_single = [len_train_single, len_val_single, len_test_single]\nlen_single = pd.DataFrame(len_single, columns=['samples'])\nlen_single['split'] = ['Train', 'Validation', 'Test'] \nlen_single","metadata":{"execution":{"iopub.status.busy":"2022-08-12T18:32:31.987919Z","iopub.execute_input":"2022-08-12T18:32:31.988366Z","iopub.status.idle":"2022-08-12T18:32:32.174194Z","shell.execute_reply.started":"2022-08-12T18:32:31.988327Z","shell.execute_reply":"2022-08-12T18:32:32.172949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = preprocess_inputs(mvsa_multiple_features[0][0], mvsa_multiple_features[0][1], mvsa_multiple_multimodal_labels, smote=True)['texts']\nlen_train_multiple = x[0].shape[0]\nlen_val_multiple = x[1].shape[0]\nlen_test_multiple = x[2].shape[0]\nlen_multiple = [len_train_multiple, len_val_multiple, len_test_multiple]\nlen_multiple = pd.DataFrame(len_multiple, columns=['samples'])\nlen_multiple['split'] = ['Train', 'Validation', 'Test'] \nlen_multiple","metadata":{"execution":{"iopub.status.busy":"2022-08-12T18:35:31.028644Z","iopub.execute_input":"2022-08-12T18:35:31.029631Z","iopub.status.idle":"2022-08-12T18:35:31.758752Z","shell.execute_reply.started":"2022-08-12T18:35:31.029576Z","shell.execute_reply":"2022-08-12T18:35:31.757611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(len_single, values='samples', names='split', title='Biểu đồ số lượng dữ liệu dùng trong tập train, val, test MVSA-Single')\nfig.update_layout(margin_b=25, margin_t=50, margin_l=25, margin_r=25, width=WIDTH, height=HEIGHT)\nfig.update_layout(legend_title='Tập dữ liệu')\nfig.update_traces(textinfo='value')\nfig.write_html('./plots/single-pie-plot.html')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T18:35:24.631624Z","iopub.execute_input":"2022-08-12T18:35:24.632109Z","iopub.status.idle":"2022-08-12T18:35:24.70995Z","shell.execute_reply.started":"2022-08-12T18:35:24.632067Z","shell.execute_reply":"2022-08-12T18:35:24.708903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(len_multiple, values='samples', names='split', title='Biểu đồ số lượng dữ liệu dùng trong tập train, val, test MVSA-Multiple')\nfig.update_layout(margin_b=25, margin_t=50, margin_l=25, margin_r=25, width=WIDTH, height=HEIGHT)\nfig.update_layout(legend_title='Tập dữ liệu')\nfig.update_traces(textinfo='value')\nfig.write_html('./plots/multiple-pie-plot.html')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T18:35:33.83045Z","iopub.execute_input":"2022-08-12T18:35:33.831758Z","iopub.status.idle":"2022-08-12T18:35:33.92221Z","shell.execute_reply.started":"2022-08-12T18:35:33.83169Z","shell.execute_reply":"2022-08-12T18:35:33.920677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fusion and unimodal all in plots","metadata":{}},{"cell_type":"code","source":"def get_scores_single(feature, score):\n    return df1_single_scores_image.iloc[feature, score], \\\n            df1_single_scores_text.iloc[feature, score], \\\n            df1_single_scores_LF.iloc[feature, score], \\\n            df0_single_scores_IF.iloc[feature, score], \\\n            df2_single_scores_HF.iloc[feature, score]\n\ndef get_scores_multiple(feature, score):\n    return df1_multiple_scores_image.iloc[feature, score], \\\n            df1_multiple_scores_text.iloc[feature, score], \\\n            df1_multiple_scores_LF.iloc[feature, score], \\\n            df0_multiple_scores_IF.iloc[feature, score], \\\n            df2_multiple_scores_HF.iloc[feature, score]\n\nmodel_names = ['Image', 'Text', 'LF', 'IF', 'HF']","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:23.756812Z","iopub.execute_input":"2022-08-04T04:33:23.757148Z","iopub.status.idle":"2022-08-04T04:33:23.765841Z","shell.execute_reply.started":"2022-08-04T04:33:23.757118Z","shell.execute_reply":"2022-08-04T04:33:23.764474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MVSA-Single","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:23.767321Z","iopub.execute_input":"2022-08-04T04:33:23.767708Z","iopub.status.idle":"2022-08-04T04:33:23.777938Z","shell.execute_reply.started":"2022-08-04T04:33:23.767652Z","shell.execute_reply":"2022-08-04T04:33:23.776741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_acc_single = pd.DataFrame(get_scores_single(0, 0), columns=['Score'])\ndf_acc_single['Model'] = model_names\ndf_acc_single['Feature'] = feature_names[0]\n\nfor i, v in enumerate(feature_names):\n    if i == 0:\n        continue\n    x = pd.DataFrame(get_scores_single(i, 0), columns=['Score'])\n    x['Model'] = model_names\n    x['Feature'] = v\n    df_acc_single = df_acc_single.append(x)\n\n# fig = px.line(df_acc_single, x='Model', y='Score', color='Feature', markers=True)\n# fig.update_layout(margin_b=25, margin_t=50, margin_l=25, margin_r=25, width=WIDTH, height=HEIGHT)\n# fig.update_layout(title='Biểu đồ so sánh Accuracy giữa các mô hình và đặc trưng MVSA-Single', \n#                   legend_title='Đặc trưng', xaxis_title='Mô hình', yaxis_title='Accuracy')\n# fig.write_html('./plots/single-acc-plot.html')\n# fig.show()\n\ndf_f1_single = pd.DataFrame(get_scores_single(0, 2), columns=['Score'])\ndf_f1_single['Model'] = model_names\ndf_f1_single['Feature'] = feature_names[0]\n\nfor i, v in enumerate(feature_names):\n    if i == 0:\n        continue\n    x = pd.DataFrame(get_scores_single(i, 2), columns=['Score'])\n    x['Model'] = model_names\n    x['Feature'] = v\n    df_f1_single = df_f1_single.append(x)\n    \n# fig = px.line(df_f1_single, x='Model', y='Score', color='Feature', markers=True)\n# fig.update_layout(margin_b=25, margin_t=50, margin_l=25, margin_r=25, width=WIDTH, height=HEIGHT)\n# fig.update_layout(legend_title='Đặc trưng', xaxis_title='Mô hình', yaxis_title='F1-weighted')\n# fig.write_html('./plots/single-f1-plot.html')\n# fig.show()\n\ndf_acc_single['score_name'] = 'Accuracy'\ndf_f1_single['score_name'] = 'F1-weighted'\ndf_score_single = df_acc_single.append(df_f1_single)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:23.781662Z","iopub.execute_input":"2022-08-04T04:33:23.782058Z","iopub.status.idle":"2022-08-04T04:33:23.819855Z","shell.execute_reply.started":"2022-08-04T04:33:23.782024Z","shell.execute_reply":"2022-08-04T04:33:23.818893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(df_score_single, x=\"Model\", y=\"Score\",\\\n              facet_col=\"score_name\",\\\n              facet_col_spacing = 0.15, color='Feature', markers=True)\nfig.update_layout(barmode='group')\nfig.update_layout(margin_b=25, margin_t=100, margin_l=25, margin_r=25, width=WIDTH+50, height=HEIGHT+50)\nfig.update_layout(title='Biểu đồ Accuracy, F1-score so sánh giữa các mô hình và đặc trưng <br>trong bộ dữ liệu MVSA-Single', \n                  legend_title='Features', xaxis_title='Model')\nfig.write_html('./plots/single-scores-plot.html')\nfig.update_layout(legend=dict(\n    yanchor=\"top\",\n    y=-0.25,\n    xanchor=\"left\",\n    x=0.35\n))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:23.821067Z","iopub.execute_input":"2022-08-04T04:33:23.822063Z","iopub.status.idle":"2022-08-04T04:33:24.016819Z","shell.execute_reply.started":"2022-08-04T04:33:23.822023Z","shell.execute_reply":"2022-08-04T04:33:24.015622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MVSA-Multiple","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:24.018475Z","iopub.execute_input":"2022-08-04T04:33:24.018818Z","iopub.status.idle":"2022-08-04T04:33:24.02473Z","shell.execute_reply.started":"2022-08-04T04:33:24.018789Z","shell.execute_reply":"2022-08-04T04:33:24.023411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_acc_multiple = pd.DataFrame(get_scores_multiple(0, 0), columns=['Score'])\ndf_acc_multiple['Model'] = model_names\ndf_acc_multiple['Feature'] = feature_names[0]\n\nfor i, v in enumerate(feature_names):\n    if i == 0:\n        continue\n    x = pd.DataFrame(get_scores_multiple(i, 0), columns=['Score'])\n    x['Model'] = model_names\n    x['Feature'] = v\n    df_acc_multiple = df_acc_multiple.append(x)\n\n# fig = px.line(df_acc_multiple, x='Model', y='Score', color='Feature', markers=True)\n# fig.update_layout(margin_b=25, margin_t=50, margin_l=25, margin_r=25, width=WIDTH, height=HEIGHT)\n# fig.update_layout(legend_title='Đặc trưng', xaxis_title='Mô hình')\n# fig.write_html('./plots/multiple-acc-plot.html')\n# fig.show()\n\ndf_f1_multiple = pd.DataFrame(get_scores_multiple(0, 2), columns=['Score'])\ndf_f1_multiple['Model'] = model_names\ndf_f1_multiple['Feature'] = feature_names[0]\n\nfor i, v in enumerate(feature_names):\n    if i == 0:\n        continue\n    x = pd.DataFrame(get_scores_multiple(i, 2), columns=['Score'])\n    x['Model'] = model_names\n    x['Feature'] = v\n    df_f1_multiple = df_f1_multiple.append(x)\n    \n# fig = px.line(df_f1_multiple, x='Model', y='Score', color='Feature', markers=True)\n# fig.update_layout(margin_b=25, margin_t=50, margin_l=25, margin_r=25, width=WIDTH, height=HEIGHT)\n# fig.update_layout(legend_title='Đặc trưng', xaxis_title='Mô hình')\n# fig.write_html('./plots/multiple-f1-plot.html')\n# fig.show()\n\ndf_acc_multiple['score_name'] = 'Accuracy'\ndf_f1_multiple['score_name'] = 'F1-weighted'\ndf_score_multiple = df_acc_multiple.append(df_f1_multiple)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:24.026463Z","iopub.execute_input":"2022-08-04T04:33:24.026928Z","iopub.status.idle":"2022-08-04T04:33:24.065037Z","shell.execute_reply.started":"2022-08-04T04:33:24.026895Z","shell.execute_reply":"2022-08-04T04:33:24.063996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(df_score_multiple, x=\"Model\", y=\"Score\",\\\n              facet_col=\"score_name\",\\\n              facet_col_spacing = 0.15, color='Feature', markers=True)\nfig.update_layout(barmode='group')\nfig.update_layout(margin_b=25, margin_t=100, margin_l=25, margin_r=25, width=WIDTH+50, height=HEIGHT+50)\nfig.update_layout(title='Biểu đồ Accuracy, F1-score so sánh giữa các mô hình và đặc trưng <br>trong bộ dữ liệu MVSA-Multiple', \n                  legend_title='Features', xaxis_title='Model')\nfig.write_html('./plots/multiple-scores-plot.html')\nfig.update_layout(legend=dict(\n    yanchor=\"top\",\n    y=-0.25,\n    xanchor=\"left\",\n    x=0.35\n))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:24.066836Z","iopub.execute_input":"2022-08-04T04:33:24.067287Z","iopub.status.idle":"2022-08-04T04:33:24.21625Z","shell.execute_reply.started":"2022-08-04T04:33:24.067245Z","shell.execute_reply":"2022-08-04T04:33:24.21507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DenseNet201-BERT-LSTM plot","metadata":{}},{"cell_type":"code","source":"pp_single = pd.DataFrame(get_scores_single(2, 0), columns=['Accuracy'])\npp_single['F1-weighted'] = get_scores_single(2, 2)\npp_single.index = model_names\nopen('./tables/single-densenet201-bert-lstm-scores.html', 'w').write(style_dataframe_out(pp_single).to_html())\nstyle_dataframe_out(pp_single)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:24.218465Z","iopub.execute_input":"2022-08-04T04:33:24.218978Z","iopub.status.idle":"2022-08-04T04:33:24.250839Z","shell.execute_reply.started":"2022-08-04T04:33:24.21893Z","shell.execute_reply":"2022-08-04T04:33:24.249719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pp_multiple = pd.DataFrame(get_scores_multiple(2, 0), columns=['Accuracy'])\npp_multiple['F1-weighted'] = get_scores_multiple(2, 2)\npp_multiple.index = model_names\nopen('./tables/multiple-densenet201-bert-lstm-scores.html', 'w').write(style_dataframe_out(pp_multiple).to_html())\nstyle_dataframe_out(pp_multiple)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:24.252202Z","iopub.execute_input":"2022-08-04T04:33:24.252491Z","iopub.status.idle":"2022-08-04T04:33:24.280415Z","shell.execute_reply.started":"2022-08-04T04:33:24.252465Z","shell.execute_reply":"2022-08-04T04:33:24.279569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pp_multiple1 = pd.DataFrame(get_scores_multiple(3, 0), columns=['Accuracy'])\npp_multiple1['F1-weighted'] = get_scores_multiple(3, 2)\npp_multiple1.index = model_names\nopen('./tables/multiple-densenet201-bert-pos-lstm-scores.html', 'w').write(style_dataframe_out(pp_multiple1).to_html())\nstyle_dataframe_out(pp_multiple1)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:24.281655Z","iopub.execute_input":"2022-08-04T04:33:24.282026Z","iopub.status.idle":"2022-08-04T04:33:24.311418Z","shell.execute_reply.started":"2022-08-04T04:33:24.281993Z","shell.execute_reply":"2022-08-04T04:33:24.31042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text plots\n","metadata":{}},{"cell_type":"code","source":"df1_single_scores_text","metadata":{"execution":{"iopub.status.busy":"2022-08-04T04:33:24.312705Z","iopub.execute_input":"2022-08-04T04:33:24.313469Z","iopub.status.idle":"2022-08-04T04:33:24.326545Z","shell.execute_reply.started":"2022-08-04T04:33:24.313434Z","shell.execute_reply":"2022-08-04T04:33:24.325145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_single = df1_single_scores_text.drop(df1_single_scores_text.index[0], axis=0).drop(df1_single_scores_text.index[2], axis=0).drop(columns=['F1-macro'])\ndf_single = pd.DataFrame(np.array([[0.501109, 0.433083]]), columns=['Accuracy', 'F1-weighted'], index=['glove']).append(df_single)\ndf_single['Đặc trưng'] = df_single.index\ndf_single['Bộ dữ liệu'] = 'MVSA-Single'","metadata":{"execution":{"iopub.status.busy":"2022-08-04T05:21:02.853564Z","iopub.execute_input":"2022-08-04T05:21:02.853995Z","iopub.status.idle":"2022-08-04T05:21:02.866635Z","shell.execute_reply.started":"2022-08-04T05:21:02.853958Z","shell.execute_reply":"2022-08-04T05:21:02.865341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_multiple = df1_multiple_scores_text.drop(df1_multiple_scores_text.index[0], axis=0).drop(df1_multiple_scores_text.index[2], axis=0).drop(columns=['F1-macro'])\ndf_multiple = pd.DataFrame(np.array([[0.453584, 0.454950]]), columns=['Accuracy', 'F1-weighted'], index=['glove']).append(df_multiple)\ndf_multiple['Đặc trưng'] = df_multiple.index\ndf_multiple['Bộ dữ liệu'] = 'MVSA-Multiple'","metadata":{"execution":{"iopub.status.busy":"2022-08-04T05:21:03.000442Z","iopub.execute_input":"2022-08-04T05:21:03.001873Z","iopub.status.idle":"2022-08-04T05:21:03.016075Z","shell.execute_reply.started":"2022-08-04T05:21:03.001818Z","shell.execute_reply":"2022-08-04T05:21:03.01457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df_single, df_multiple])","metadata":{"execution":{"iopub.status.busy":"2022-08-04T05:21:18.924946Z","iopub.execute_input":"2022-08-04T05:21:18.925396Z","iopub.status.idle":"2022-08-04T05:21:18.933195Z","shell.execute_reply.started":"2022-08-04T05:21:18.925364Z","shell.execute_reply":"2022-08-04T05:21:18.931665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(df, x=\"Đặc trưng\", y=[\"Accuracy\", \"F1-weighted\"], facet_col=\"Bộ dữ liệu\", facet_col_spacing = 0.15)\nfig.update_layout(barmode = 'group')\n# fig.update_layout(bargap=0.2)\nfig.update_layout(margin_b=25, margin_t=50, margin_l=25, margin_r=25, width=WIDTH, height=HEIGHT)\nfig.update_layout(title='Biểu đồ kết quả đánh giá các đặc trưng của dữ liệu văn bản',\n              yaxis_title='Điểm', legend_title='Độ đo')\nfig.write_html('./plots/text-scores-plot.html')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-04T05:21:21.480423Z","iopub.execute_input":"2022-08-04T05:21:21.481845Z","iopub.status.idle":"2022-08-04T05:21:21.618056Z","shell.execute_reply.started":"2022-08-04T05:21:21.481777Z","shell.execute_reply":"2022-08-04T05:21:21.616935Z"},"trusted":true},"execution_count":null,"outputs":[]}]}