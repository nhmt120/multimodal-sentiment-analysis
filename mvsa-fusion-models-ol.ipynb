{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c63733",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-04T17:26:53.928717Z",
     "iopub.status.busy": "2022-07-04T17:26:53.928128Z",
     "iopub.status.idle": "2022-07-04T17:27:03.959476Z",
     "shell.execute_reply": "2022-07-04T17:27:03.958550Z"
    },
    "papermill": {
     "duration": 10.046157,
     "end_time": "2022-07-04T17:27:03.961865",
     "exception": false,
     "start_time": "2022-07-04T17:26:53.915708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 61\n",
    "\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk import tokenize\n",
    "from IPython.display import display_html\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
    "from tensorflow.python.keras.layers import Layer, InputSpec, Lambda\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RepeatedKFold, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import initializers,regularizers,constraints\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Reshape, Input, Embedding, Flatten, Dense, Dropout, BatchNormalization, Activation #, merge\n",
    "from keras.layers import TimeDistributed, LSTM, GRU, Bidirectional, Convolution1D, MaxPooling1D, MaxPooling2D\n",
    "from keras.layers.core import RepeatVector #, Reshape\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(SEED) \n",
    "    python_random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "# from tensorflow.keras import Model\n",
    "# from attention import Attention_input1, Attention_input2\n",
    "# from keras.optimizers import SGD, RMSprop, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953c7a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:03.980252Z",
     "iopub.status.busy": "2022-07-04T17:27:03.979758Z",
     "iopub.status.idle": "2022-07-04T17:27:03.984639Z",
     "shell.execute_reply": "2022-07-04T17:27:03.983830Z"
    },
    "papermill": {
     "duration": 0.016091,
     "end_time": "2022-07-04T17:27:03.986694",
     "exception": false,
     "start_time": "2022-07-04T17:27:03.970603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e99902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:04.004484Z",
     "iopub.status.busy": "2022-07-04T17:27:04.004217Z",
     "iopub.status.idle": "2022-07-04T17:27:04.012318Z",
     "shell.execute_reply": "2022-07-04T17:27:04.011429Z"
    },
    "papermill": {
     "duration": 0.019408,
     "end_time": "2022-07-04T17:27:04.014363",
     "exception": false,
     "start_time": "2022-07-04T17:27:03.994955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_hdf5(path):\n",
    "    read_file = h5py.File(path, 'r')\n",
    "    \n",
    "    feature_names = list(read_file.keys())\n",
    "    loaded_data = []\n",
    "    \n",
    "    for name in feature_names:\n",
    "        dataset = read_file[name][:]\n",
    "        if dataset.dtype == np.dtype('object'):\n",
    "            dataset = np.array([x.decode('UTF-8') for x in dataset])            \n",
    "        loaded_data.append((name, dataset))\n",
    "\n",
    "    return loaded_data\n",
    "\n",
    "def loadz(path):\n",
    "    data = np.load(path)['arr_0']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948420dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:04.033292Z",
     "iopub.status.busy": "2022-07-04T17:27:04.032525Z",
     "iopub.status.idle": "2022-07-04T17:27:04.041797Z",
     "shell.execute_reply": "2022-07-04T17:27:04.040893Z"
    },
    "papermill": {
     "duration": 0.02066,
     "end_time": "2022-07-04T17:27:04.043666",
     "exception": false,
     "start_time": "2022-07-04T17:27:04.023006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_labels(path):\n",
    "    data = read_hdf5(path)\n",
    "\n",
    "    for x in data:\n",
    "        if x[0] == 'multimodal-labels':\n",
    "            labels = x[1]\n",
    "        if x[0] == 'text-labels':\n",
    "            text_labels = x[1]\n",
    "        if x[0] == 'image-labels':\n",
    "            image_labels = x[1]\n",
    "        \n",
    "    return labels, text_labels, image_labels\n",
    "\n",
    "def merge_mvsa(mvsa_single, mvsa_multiple):\n",
    "    mvsa = np.concatenate((mvsa_single, mvsa_multiple), axis=0)\n",
    "    return mvsa\n",
    "\n",
    "def load_mvsa_feature(feature_name, merge=False):\n",
    "    folder_path = os.path.join('../input/mvsa-features/', feature_name)\n",
    "    single_file = 'mvsa-single-{}.npz'.format(feature_name)\n",
    "    multiple_file = 'mvsa-multiple-{}.npz'.format(feature_name)\n",
    "    mvsa_single = loadz(os.path.join(folder_path, single_file))\n",
    "    mvsa_multiple = loadz(os.path.join(folder_path, multiple_file))\n",
    "    \n",
    "    if merge == True:\n",
    "        return merge_mvsa(mvsa_single, mvsa_multiple)\n",
    "    \n",
    "    return mvsa_single, mvsa_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d145f822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:04.061669Z",
     "iopub.status.busy": "2022-07-04T17:27:04.061410Z",
     "iopub.status.idle": "2022-07-04T17:27:04.066801Z",
     "shell.execute_reply": "2022-07-04T17:27:04.065831Z"
    },
    "papermill": {
     "duration": 0.016776,
     "end_time": "2022-07-04T17:27:04.068968",
     "exception": false,
     "start_time": "2022-07-04T17:27:04.052192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# e.g. validation_split=0.1 -----> 8:1:1 ratio of train, val, test\n",
    "def split_data(data, validation_split):\n",
    "    num_val = int(validation_split * data.shape[0])\n",
    "    data_train = data[:-(num_val*2)]\n",
    "    data_val = data[-(num_val*2):-(num_val)]\n",
    "    data_test = data[-num_val:]\n",
    "    return data_train, data_val, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d25d5561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:04.087227Z",
     "iopub.status.busy": "2022-07-04T17:27:04.086963Z",
     "iopub.status.idle": "2022-07-04T17:27:04.096179Z",
     "shell.execute_reply": "2022-07-04T17:27:04.095187Z"
    },
    "papermill": {
     "duration": 0.02034,
     "end_time": "2022-07-04T17:27:04.098027",
     "exception": false,
     "start_time": "2022-07-04T17:27:04.077687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_average(weights, probs):\n",
    "    ''' Calculate the weighted average probability distribution from all input probs and its weights \n",
    "    weights: weights list (or array)\n",
    "    probs: probability distributions array list\n",
    "    '''\n",
    "    output_probs = []\n",
    "    weighted_probs = [probs[i] * weights[i] for i in range(len(weights))]\n",
    "    for i in range(len(probs[0])):\n",
    "        sum_prob = np.zeros(len(probs[0][0]))\n",
    "        for j in range(len(weights)):\n",
    "            sum_prob = np.sum((sum_prob, weighted_probs[j][i]), axis=0)\n",
    "        output_probs.append(sum_prob)\n",
    "    return np.asarray(output_probs, dtype='float32')\n",
    "\n",
    "def get_average_weights(*scores, inverse=False):\n",
    "    ''' Get the corresponding weight of each input score \n",
    "    inverse: (bool) get inverse weights value in case of the smaller score value, the bigger weight value (such as model loss)\n",
    "    '''\n",
    "    \n",
    "    weights = []\n",
    "    for score in scores:\n",
    "        weights.append(score/np.sum(scores))\n",
    "    \n",
    "    if inverse == True:\n",
    "        inverse_weights = []\n",
    "        inverse = [1/weight for weight in weights]\n",
    "        for inv in inverse:\n",
    "            inverse_weights.append(inv/np.sum(inverse))\n",
    "        weights = inverse_weights\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f3a3a24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:04.117097Z",
     "iopub.status.busy": "2022-07-04T17:27:04.116193Z",
     "iopub.status.idle": "2022-07-04T17:27:10.340170Z",
     "shell.execute_reply": "2022-07-04T17:27:10.336879Z"
    },
    "papermill": {
     "duration": 6.236627,
     "end_time": "2022-07-04T17:27:10.343262",
     "exception": false,
     "start_time": "2022-07-04T17:27:04.106635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 17:27:04.223842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-04 17:27:04.224929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-04 17:27:04.225601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-04 17:27:04.226477: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-04 17:27:04.226780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-04 17:27:04.227482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-04 17:27:04.228128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-04 17:27:09.990079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-04 17:27:09.991008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-04 17:27:09.991723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-04 17:27:09.992358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15047 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "f1_macro = tfa.metrics.F1Score(num_classes=NUM_CLASSES, average='macro', name='f1_macro')\n",
    "f1_weighted = tfa.metrics.F1Score(num_classes=NUM_CLASSES, average='weighted', name='f1_weighted')\n",
    "    \n",
    "def create_model_text(input_shape, lstm=True):\n",
    "    text_input = Input(shape=input_shape)\n",
    "    if lstm == True:\n",
    "        reshape_text = Reshape((1, -1)) (text_input)\n",
    "        lstm = LSTM(NUM_LSTM) (reshape_text)\n",
    "        outputs = Dense(NUM_CLASSES, activation='softmax') (lstm)\n",
    "    else:\n",
    "        outputs = Dense(NUM_CLASSES, activation='softmax') (text_input)\n",
    "    model = Model(text_input, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_macro, f1_weighted])\n",
    "    return model\n",
    "\n",
    "def create_model_image(input_shape):\n",
    "    image_input = Input(shape=input_shape)\n",
    "    outputs = Dense(NUM_CLASSES, activation='softmax') (image_input)\n",
    "    model = Model(image_input, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_macro, f1_weighted])\n",
    "    return model\n",
    "\n",
    "def create_model_IF(text_shape, image_shape, lstm=True):\n",
    "    image_input = Input(shape=image_shape)\n",
    "    text_input = Input(shape=text_shape)\n",
    "    if lstm == True:\n",
    "        text_reshape = Reshape((1, -1)) (text_input)\n",
    "        text_lstm = LSTM(NUM_LSTM) (text_reshape)\n",
    "#     text_lstm = Dropout(DROPOUT_RATE) (text_lstm)\n",
    "        text_image_concat = tf.keras.layers.Concatenate(axis=1)([text_lstm, image_input])\n",
    "    else:\n",
    "        text_image_concat = tf.keras.layers.Concatenate(axis=1)([text_input, image_input])\n",
    "    concat_self_attention = tf.keras.layers.Attention() ([text_image_concat, text_image_concat])\n",
    "#     concat_self_attention = Dropout(DROPOUT_RATE) (concat_self_attention)\n",
    "    outputs = Dense(NUM_CLASSES, activation='softmax') (concat_self_attention)\n",
    "    model = Model([text_input, image_input], outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_macro, f1_weighted])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cd2ee2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:10.363061Z",
     "iopub.status.busy": "2022-07-04T17:27:10.362124Z",
     "iopub.status.idle": "2022-07-04T17:27:10.376593Z",
     "shell.execute_reply": "2022-07-04T17:27:10.375713Z"
    },
    "papermill": {
     "duration": 0.026458,
     "end_time": "2022-07-04T17:27:10.378631",
     "exception": false,
     "start_time": "2022-07-04T17:27:10.352173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_and_evaluate_IF(name, X1, X2, y, verbose=0, lstm=True):\n",
    "    '''  Train and test Intermediate Fusion model Multimodal Labels \n",
    "    X1: text input\n",
    "    X2: image input\n",
    "    y: multimodal labels\n",
    "    '''\n",
    "    y = le.fit_transform(y)\n",
    "    y = to_categorical(np.asarray(y))\n",
    "    \n",
    "    X1_train, X1_val, X1_test = split_data(X1, VALIDATION_SPLIT)\n",
    "    X2_train, X2_val, X2_test = split_data(X2, VALIDATION_SPLIT)\n",
    "    y_train, y_val, y_test = split_data(y, VALIDATION_SPLIT)\n",
    "    \n",
    "    if lstm == False:\n",
    "        model = create_model_IF(X1_train.shape[1:], X2_train.shape[1:], lstm=False)\n",
    "    else:\n",
    "        model = create_model_IF(X1_train.shape[1:], X2_train.shape[1:])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n",
    "    checkpoint = ModelCheckpoint('./model_checkpoint/{}.h5'.format(name), save_best_only=True, verbose=verbose)\n",
    "    \n",
    "    history = model.fit([X1_train, X2_train], y_train, validation_data=([X1_val, X2_val], y_val), \n",
    "                        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n",
    "                        callbacks=[checkpoint, early_stopping])\n",
    "    if verbose == 1:\n",
    "        best_epoch = np.argmin(history.history['val_loss'])\n",
    "        print('\\nCheckpoint loaded at epoch:', best_epoch)\n",
    "        \n",
    "    return history, evaluate_model_IF(model, X1_test, X2_test, y_test, checkpoint=name, verbose=verbose)\n",
    "\n",
    "def evaluate_model_IF(model, X_texts, X_images, y_test, checkpoint=None, verbose=1):\n",
    "    if checkpoint is not None:\n",
    "        model = load_model('./model_checkpoint/{}.h5'.format(checkpoint))\n",
    "    \n",
    "    loss, acc, f1_macro, f1_weighted = model.evaluate([X_texts, X_images], y_test, verbose=verbose)\n",
    "\n",
    "    if verbose == 1:\n",
    "        print('Loss:', loss)\n",
    "        print('Accuracy:', acc)\n",
    "        print('Macro F1-score:', f1_macro)\n",
    "        print('Weighted F1-score:', f1_weighted)\n",
    "\n",
    "        y_pred = model.predict([X_texts, X_images])\n",
    "        matrix = confusion_matrix(le.inverse_transform(y_test.argmax(axis=1)), le.inverse_transform(y_pred.argmax(axis=1)), \n",
    "                                  labels=list(le.classes_))\n",
    "        cm_disp = ConfusionMatrixDisplay(confusion_matrix=matrix,\n",
    "                                  display_labels=list(le.classes_))\n",
    "        cm_disp.plot()\n",
    "        plt.show()\n",
    "        \n",
    "    return loss, acc, f1_macro, f1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4bbc508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:10.396547Z",
     "iopub.status.busy": "2022-07-04T17:27:10.396295Z",
     "iopub.status.idle": "2022-07-04T17:27:10.411810Z",
     "shell.execute_reply": "2022-07-04T17:27:10.410970Z"
    },
    "papermill": {
     "duration": 0.026852,
     "end_time": "2022-07-04T17:27:10.413724",
     "exception": false,
     "start_time": "2022-07-04T17:27:10.386872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_and_evaluate_LF(name, X1, X2, y, y1, y2, verbose=0, lstm=True):\n",
    "    ''' Train Late Fusion model with Original Labels of each modality and test with Multimodal Labels \n",
    "    X1: text input\n",
    "    X2: image input\n",
    "    y: multimodal labels\n",
    "    y1: text labels\n",
    "    y2: image labels\n",
    "    verbose: 0 or 1 to print tracking on progress\n",
    "    '''\n",
    "    y = le.fit_transform(y)\n",
    "    y = to_categorical(np.asarray(y))\n",
    "    \n",
    "    y1 = le.fit_transform(y1)\n",
    "    y1 = to_categorical(np.asarray(y1))\n",
    "    \n",
    "    y2 = le.fit_transform(y2)\n",
    "    y2 = to_categorical(np.asarray(y2))\n",
    "\n",
    "    X1_train, X1_val, X1_test = split_data(X1, VALIDATION_SPLIT)\n",
    "    X2_train, X2_val, X2_test = split_data(X2, VALIDATION_SPLIT)\n",
    "    y_train, y_val, y_test = split_data(y, VALIDATION_SPLIT)\n",
    "    y1_train, y1_val, y1_test = split_data(y1, VALIDATION_SPLIT)\n",
    "    y2_train, y2_val, y2_test = split_data(y2, VALIDATION_SPLIT)\n",
    "\n",
    "    if lstm == False:\n",
    "        model_text = create_model_text(X1_train.shape[1:], lstm=False)\n",
    "    else:\n",
    "        model_text = create_model_text(X1_train.shape[1:])\n",
    "    model_image = create_model_image(X2_train.shape[1:])\n",
    "\n",
    "    early_stopping1 = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n",
    "    early_stopping2 = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n",
    "    checkpoint_text = ModelCheckpoint('./model_checkpoint/{}-text.h5'.format(name), save_best_only=True, verbose=verbose)\n",
    "    checkpoint_image = ModelCheckpoint('./model_checkpoint/{}-image.h5'.format(name), save_best_only=True, verbose=verbose)\n",
    "    \n",
    "    history_text = model_text.fit(X1_train, y1_train, validation_data=(X1_val, y1_val), \n",
    "                                  epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n",
    "                                  callbacks=[checkpoint_text, early_stopping1])\n",
    "    \n",
    "    history_image = model_image.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), \n",
    "                                    epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n",
    "                                    callbacks=[checkpoint_image, early_stopping2])\n",
    "    \n",
    "    best_val_loss_text = np.min(history_text.history['val_loss'])\n",
    "    best_val_loss_image = np.min(history_image.history['val_loss'])\n",
    "\n",
    "    weights = get_average_weights(best_val_loss_text, best_val_loss_image, inverse=True)\n",
    "\n",
    "    model_text = load_model('./model_checkpoint/{}-text.h5'.format(name))\n",
    "    model_image = load_model('./model_checkpoint/{}-image.h5'.format(name))\n",
    "\n",
    "    y_pred_text = model_text.predict(X1_test)\n",
    "    y_pred_image = model_image.predict(X2_test)\n",
    "\n",
    "    y_pred = weighted_average(weights, np.asarray([y_pred_text, y_pred_image], dtype='float32'))\n",
    "\n",
    "    best_epoch_text = np.argmin(history_text.history['val_loss'])\n",
    "    best_epoch_image = np.argmin(history_image.history['val_loss'])\n",
    "\n",
    "    if verbose == 1:\n",
    "        print('Checkpoint of text model loaded at epoch:', best_epoch_text)\n",
    "        print('Checkpoint of image model loaded at epoch:', best_epoch_image)\n",
    "\n",
    "    return evaluate_model_LF(y_test, y_pred, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "882952c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:10.431991Z",
     "iopub.status.busy": "2022-07-04T17:27:10.431731Z",
     "iopub.status.idle": "2022-07-04T17:27:10.451341Z",
     "shell.execute_reply": "2022-07-04T17:27:10.450376Z"
    },
    "papermill": {
     "duration": 0.030888,
     "end_time": "2022-07-04T17:27:10.453154",
     "exception": false,
     "start_time": "2022-07-04T17:27:10.422266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_and_evaluate_HF(name, X1, X2, y, y1, y2, verbose=0, lstm=True):\n",
    "    ''' Train Hybrid Fusion model with Original Labels of each modality and test with Multimodal Labels \n",
    "    X1: text input\n",
    "    X2: image input\n",
    "    y: multimodal labels\n",
    "    y1: text labels\n",
    "    y2: image labels\n",
    "    lstm: (bool) create text model with LSTM layer or not\n",
    "    verbose: 0 or 1 to print tracking on progress\n",
    "    '''\n",
    "    y = le.fit_transform(y)\n",
    "    y = to_categorical(np.asarray(y))\n",
    "    \n",
    "    y1 = le.fit_transform(y1)\n",
    "    y1 = to_categorical(np.asarray(y1))\n",
    "    \n",
    "    y2 = le.fit_transform(y2)\n",
    "    y2 = to_categorical(np.asarray(y2))\n",
    "    \n",
    "    X1_train, X1_val, X1_test = split_data(X1, VALIDATION_SPLIT)\n",
    "    X2_train, X2_val, X2_test = split_data(X2, VALIDATION_SPLIT)\n",
    "    y_train, y_val, y_test = split_data(y, VALIDATION_SPLIT)\n",
    "    y1_train, y1_val, y1_test = split_data(y1, VALIDATION_SPLIT)\n",
    "    y2_train, y2_val, y2_test = split_data(y2, VALIDATION_SPLIT)\n",
    "\n",
    "    model_image = create_model_image(X2_train.shape[1:])\n",
    "    if lstm == False:\n",
    "        model_text = create_model_text(X1_train.shape[1:], lstm=False)\n",
    "        model_IF = create_model_IF(X1_train.shape[1:], X2_train.shape[1:], lstm=False)\n",
    "    model_text = create_model_text(X1_train.shape[1:])\n",
    "    model_IF = create_model_IF(X1_train.shape[1:], X2_train.shape[1:])\n",
    "    \n",
    "    early_stopping1 = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n",
    "    early_stopping2 = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n",
    "    early_stopping3 = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n",
    "\n",
    "    checkpoint_text = ModelCheckpoint('./model_checkpoint/{}-text.h5'.format(name), save_best_only=True, verbose=verbose)\n",
    "    checkpoint_image = ModelCheckpoint('./model_checkpoint/{}-image.h5'.format(name), save_best_only=True, verbose=verbose)\n",
    "    checkpoint_IF = ModelCheckpoint('./model_checkpoint/{}-IF.h5'.format(name), save_best_only=True, verbose=verbose)\n",
    "\n",
    "    history_text = model_text.fit(X1_train, y1_train, validation_data=(X1_val, y1_val), \n",
    "                                  epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n",
    "                                  callbacks=[checkpoint_text, early_stopping1])\n",
    "    \n",
    "    history_image = model_image.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), \n",
    "                                    epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n",
    "                                    callbacks=[checkpoint_image, early_stopping2])\n",
    "    \n",
    "    history_IF = model_IF.fit([X1_train, X2_train], y_train, validation_data=([X1_val, X2_val], y_val), \n",
    "                              epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n",
    "                              callbacks=[checkpoint_IF, early_stopping3])\n",
    "    \n",
    "    best_val_loss_text = np.min(history_text.history['val_loss'])\n",
    "    best_val_loss_image = np.min(history_image.history['val_loss'])\n",
    "    best_val_loss_IF = np.min(history_IF.history['val_loss'])\n",
    "    \n",
    "    weights = get_average_weights(best_val_loss_text, best_val_loss_image, best_val_loss_IF,\n",
    "                                  inverse=True)\n",
    "\n",
    "    model_text = load_model('./model_checkpoint/{}-text.h5'.format(name))\n",
    "    model_image = load_model('./model_checkpoint/{}-image.h5'.format(name))\n",
    "    model_IF = load_model('./model_checkpoint/{}-IF.h5'.format(name))\n",
    "\n",
    "    y_pred_text = model_text.predict(X1_test)\n",
    "    y_pred_image = model_image.predict(X2_test)\n",
    "    y_pred_IF = model_IF.predict([X1_test, X2_test])\n",
    "\n",
    "    y_pred = weighted_average(weights, np.asarray([y_pred_text, y_pred_image, y_pred_IF], dtype='float32'))\n",
    "    \n",
    "    best_epoch_text = np.argmin(history_text.history['val_loss'])\n",
    "    best_epoch_image = np.argmin(history_image.history['val_loss'])\n",
    "    best_epoch_IF = np.argmin(history_IF.history['val_loss'])\n",
    "\n",
    "    if verbose == 1:\n",
    "        print('Checkpoint of text model loaded at epoch:', best_epoch_text)\n",
    "        print('Checkpoint of image model loaded at epoch:', best_epoch_image)\n",
    "        print('Checkpoint of IF model loaded at epoch:', best_epoch_IF)\n",
    "\n",
    "    return evaluate_model_LF(y_test, y_pred, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4275870",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:10.471527Z",
     "iopub.status.busy": "2022-07-04T17:27:10.470923Z",
     "iopub.status.idle": "2022-07-04T17:27:10.478965Z",
     "shell.execute_reply": "2022-07-04T17:27:10.478157Z"
    },
    "papermill": {
     "duration": 0.01886,
     "end_time": "2022-07-04T17:27:10.480864",
     "exception": false,
     "start_time": "2022-07-04T17:27:10.462004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_LF(y_true, y_pred, verbose=0):\n",
    "    \n",
    "    y_pred = le.inverse_transform(y_pred.argmax(axis=1))\n",
    "    y_true = le.inverse_transform(y_true.argmax(axis=1))\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    if verbose == 1:\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        matrix = confusion_matrix(y_true, y_pred,\n",
    "                                  labels=list(le.classes_))\n",
    "        cm_disp = ConfusionMatrixDisplay(confusion_matrix=matrix,\n",
    "                                  display_labels=list(le.classes_))\n",
    "        cm_disp.plot()\n",
    "        plt.show()\n",
    "\n",
    "    return acc, f1_macro, f1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742e7241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:10.498371Z",
     "iopub.status.busy": "2022-07-04T17:27:10.498131Z",
     "iopub.status.idle": "2022-07-04T17:27:10.508342Z",
     "shell.execute_reply": "2022-07-04T17:27:10.507538Z"
    },
    "papermill": {
     "duration": 0.021186,
     "end_time": "2022-07-04T17:27:10.510230",
     "exception": false,
     "start_time": "2022-07-04T17:27:10.489044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "    fig.add_subplot(1, 4, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('LOSS')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='best')\n",
    "\n",
    "    fig.add_subplot(1, 4, 2)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('ACCURACY')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='best')\n",
    "\n",
    "    fig.add_subplot(1, 4, 3)\n",
    "    plt.plot(history.history['f1_macro'])\n",
    "    plt.plot(history.history['val_f1_macro'])\n",
    "    plt.title('Macro F1-SCORE')\n",
    "    plt.ylabel('f1-macro')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='best')\n",
    "    \n",
    "    fig.add_subplot(1, 4, 4)\n",
    "    plt.plot(history.history['f1_weighted'])\n",
    "    plt.plot(history.history['val_f1_weighted'])\n",
    "    plt.title('Weighted F1-SCORE')\n",
    "    plt.ylabel('f1-weighted')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='best')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad8bf5a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:10.529915Z",
     "iopub.status.busy": "2022-07-04T17:27:10.528404Z",
     "iopub.status.idle": "2022-07-04T17:27:10.537106Z",
     "shell.execute_reply": "2022-07-04T17:27:10.536240Z"
    },
    "papermill": {
     "duration": 0.020102,
     "end_time": "2022-07-04T17:27:10.538997",
     "exception": false,
     "start_time": "2022-07-04T17:27:10.518895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def style_dataframe(dataframe):\n",
    "    return dataframe.style.highlight_max(subset=['Accuracy', 'F1-macro', 'F1-weighted'], props='color:lawngreen', axis=0)\\\n",
    "                          .highlight_min(subset=['Accuracy', 'F1-macro', 'F1-weighted'], props='color:tomato', axis=0)\n",
    "\n",
    "def display_dataframes(dfs, names=[], index=False):\n",
    "    def to_df(x):\n",
    "        if isinstance(x, pd.Series):\n",
    "            return pd.DataFrame(x)\n",
    "        else:\n",
    "            return x\n",
    "    html_str = ''\n",
    "    if names:\n",
    "        html_str += ('<tr>' + \n",
    "                     ''.join(f'<td style=\"text-align:center\">{name}</td>' for name in names) + \n",
    "                     '</tr>')\n",
    "    html_str += ('<tr>' + \n",
    "                 ''.join(f'<td style=\"vertical-align:top\"> {to_df(df).to_html()}</td>' \n",
    "                         for df in dfs) + \n",
    "                 '</tr>')\n",
    "    html_str = f'<table>{html_str}</table>'\n",
    "    html_str = html_str.replace('table','table style=\"display:inline\"')\n",
    "    display_html(html_str, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34596bc",
   "metadata": {
    "papermill": {
     "duration": 0.008256,
     "end_time": "2022-07-04T17:27:10.555811",
     "exception": false,
     "start_time": "2022-07-04T17:27:10.547555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df062bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:10.574015Z",
     "iopub.status.busy": "2022-07-04T17:27:10.573717Z",
     "iopub.status.idle": "2022-07-04T17:27:25.199792Z",
     "shell.execute_reply": "2022-07-04T17:27:25.198797Z"
    },
    "papermill": {
     "duration": 14.63803,
     "end_time": "2022-07-04T17:27:25.202165",
     "exception": false,
     "start_time": "2022-07-04T17:27:10.564135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Choose best\n",
    "# Load text feature\n",
    "mvsa_single_bert, mvsa_multiple_bert = load_mvsa_feature('bert-base')\n",
    "mvsa_single_pos_bow, mvsa_multiple_pos_bow = load_mvsa_feature('pos-bow')\n",
    "mvsa_single_pos_tfidf, mvsa_multiple_pos_tfidf = load_mvsa_feature('pos-tfidf')\n",
    "mvsa_single_ner_bow, mvsa_multiple_ner_bow = load_mvsa_feature('ner-bow')\n",
    "mvsa_single_ner_tfidf, mvsa_multiple_ner_tfidf = load_mvsa_feature('ner-tfidf')\n",
    "\n",
    "## Load image feature\n",
    "mvsa_single_vgg16, mvsa_multiple_vgg16 = load_mvsa_feature('vgg16')\n",
    "mvsa_single_vgg19, mvsa_multiple_vgg19 = load_mvsa_feature('vgg19')\n",
    "mvsa_single_resnet50, mvsa_multiple_resnet50 = load_mvsa_feature('resnet50')\n",
    "mvsa_single_resnet101, mvsa_multiple_resnet101 = load_mvsa_feature('resnet101')\n",
    "mvsa_single_resnet152, mvsa_multiple_resnet152 = load_mvsa_feature('resnet152')\n",
    "mvsa_single_densenet121, mvsa_multiple_densenet121 = load_mvsa_feature('densenet121')\n",
    "mvsa_single_densenet169, mvsa_multiple_densenet169 = load_mvsa_feature('densenet169')\n",
    "mvsa_single_densenet201, mvsa_multiple_densenet201 = load_mvsa_feature('densenet201')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b36050e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:25.221394Z",
     "iopub.status.busy": "2022-07-04T17:27:25.220570Z",
     "iopub.status.idle": "2022-07-04T17:27:25.305836Z",
     "shell.execute_reply": "2022-07-04T17:27:25.304895Z"
    },
    "papermill": {
     "duration": 0.096909,
     "end_time": "2022-07-04T17:27:25.308189",
     "exception": false,
     "start_time": "2022-07-04T17:27:25.211280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mvsa_single_bert_pos = np.concatenate((mvsa_single_bert, mvsa_single_pos_tfidf), axis=1)\n",
    "mvsa_single_bert_pos_ner = np.concatenate((mvsa_single_bert, mvsa_single_pos_tfidf, mvsa_single_ner_tfidf), axis=1)\n",
    "\n",
    "mvsa_multiple_bert_pos = np.concatenate((mvsa_multiple_bert, mvsa_multiple_pos_tfidf), axis=1)\n",
    "mvsa_multiple_bert_pos_ner = np.concatenate((mvsa_multiple_bert, mvsa_multiple_pos_tfidf, mvsa_multiple_ner_tfidf), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e717558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:25.326820Z",
     "iopub.status.busy": "2022-07-04T17:27:25.326528Z",
     "iopub.status.idle": "2022-07-04T17:27:25.462032Z",
     "shell.execute_reply": "2022-07-04T17:27:25.461091Z"
    },
    "papermill": {
     "duration": 0.147517,
     "end_time": "2022-07-04T17:27:25.464271",
     "exception": false,
     "start_time": "2022-07-04T17:27:25.316754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mvsa_single_multimodal_labels, mvsa_single_text_labels, mvsa_single_image_labels = load_labels('../input/mvsa-features/labels/mvsa-single-labels.hdf5')\n",
    "mvsa_multiple_multimodal_labels, mvsa_multiple_text_labels, mvsa_multiple_image_labels = load_labels('../input/mvsa-features/labels/mvsa-multiple-labels.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "424fd135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:25.482731Z",
     "iopub.status.busy": "2022-07-04T17:27:25.481992Z",
     "iopub.status.idle": "2022-07-04T17:27:25.486917Z",
     "shell.execute_reply": "2022-07-04T17:27:25.486095Z"
    },
    "papermill": {
     "duration": 0.015963,
     "end_time": "2022-07-04T17:27:25.488820",
     "exception": false,
     "start_time": "2022-07-04T17:27:25.472857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mvsa_single_text_features = np.concatenate((mvsa_single_bert, mvsa_single_pos_tfidf), axis=1)\n",
    "# mvsa_multiple_text_features = np.concatenate((mvsa_multiple_bert, mvsa_multiple_pos_tfidf), axis=1)\n",
    "\n",
    "# mvsa_single_image_features = mvsa_single_densenet201\n",
    "# mvsa_multiple_image_features = mvsa_multiple_densenet201\n",
    "\n",
    "# print('Text vector shape:', mvsa_single_text_features.shape[1:])\n",
    "# print('Image vector shape:', mvsa_single_image_features.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d37d2c87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:25.506593Z",
     "iopub.status.busy": "2022-07-04T17:27:25.506257Z",
     "iopub.status.idle": "2022-07-04T17:27:25.512248Z",
     "shell.execute_reply": "2022-07-04T17:27:25.511259Z"
    },
    "papermill": {
     "duration": 0.01749,
     "end_time": "2022-07-04T17:27:25.514477",
     "exception": false,
     "start_time": "2022-07-04T17:27:25.496987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare all features data\n",
    "\n",
    "feature_names = ['resnet152-bert', 'resnet152-bert-lstm', 'densenet201-bert-pos-lstm', 'densenet201-bert-pos-ner-lstm']\n",
    "\n",
    "mvsa_single_features = [[mvsa_single_bert, mvsa_single_resnet152],\n",
    "                        [mvsa_single_bert, mvsa_single_resnet152],\n",
    "                        [mvsa_single_bert_pos, mvsa_single_densenet201],\n",
    "                        [mvsa_single_bert_pos_ner, mvsa_single_densenet201]]\n",
    "\n",
    "mvsa_multiple_features = [[mvsa_multiple_bert, mvsa_multiple_resnet152],\n",
    "                          [mvsa_multiple_bert, mvsa_multiple_resnet152],\n",
    "                          [mvsa_multiple_bert_pos, mvsa_multiple_densenet201],\n",
    "                          [mvsa_multiple_bert_pos_ner, mvsa_multiple_densenet201]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f48f82e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:25.531982Z",
     "iopub.status.busy": "2022-07-04T17:27:25.531725Z",
     "iopub.status.idle": "2022-07-04T17:27:25.537207Z",
     "shell.execute_reply": "2022-07-04T17:27:25.536408Z"
    },
    "papermill": {
     "duration": 0.016599,
     "end_time": "2022-07-04T17:27:25.539197",
     "exception": false,
     "start_time": "2022-07-04T17:27:25.522598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(mvsa_single_multimodal_labels)\n",
    "NUM_CLASSES = len(le.classes_) # = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3dd9dcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:25.558820Z",
     "iopub.status.busy": "2022-07-04T17:27:25.557290Z",
     "iopub.status.idle": "2022-07-04T17:27:25.563171Z",
     "shell.execute_reply": "2022-07-04T17:27:25.562257Z"
    },
    "papermill": {
     "duration": 0.017385,
     "end_time": "2022-07-04T17:27:25.565073",
     "exception": false,
     "start_time": "2022-07-04T17:27:25.547688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reset_seeds()\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "VALIDATION_SPLIT = 0.1\n",
    "EARLY_STOPPING = 10\n",
    "NUM_LSTM = 128\n",
    "DROPOUT_RATE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a6b56",
   "metadata": {
    "papermill": {
     "duration": 0.008087,
     "end_time": "2022-07-04T17:27:25.581476",
     "exception": false,
     "start_time": "2022-07-04T17:27:25.573389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Intermediate Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab47b5b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:25.599245Z",
     "iopub.status.busy": "2022-07-04T17:27:25.599003Z",
     "iopub.status.idle": "2022-07-04T17:27:50.772718Z",
     "shell.execute_reply": "2022-07-04T17:27:50.771539Z"
    },
    "papermill": {
     "duration": 25.185241,
     "end_time": "2022-07-04T17:27:50.774837",
     "exception": false,
     "start_time": "2022-07-04T17:27:25.589596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVSA-Single with Intermediate Fusion\n",
      "\n",
      "MVSA-Single: resnet152-bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 17:27:25.793642: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MVSA-Single: resnet152-bert-lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 17:27:32.954700: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MVSA-Single: densenet201-bert-pos-lstm\n",
      "\n",
      "MVSA-Single: densenet201-bert-pos-ner-lstm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MVSA-Single with Intermediate Fusion\\n')\n",
    "scores = []\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    print('MVSA-Single:', feature_names[i])\n",
    "    if 'lstm' in feature_names[i]:\n",
    "        _, score = run_and_evaluate_IF('single-IF-' + feature_names[i], mvsa_single_features[i][0], mvsa_single_features[i][1], \n",
    "                                     mvsa_single_multimodal_labels,\n",
    "                                     verbose=0)\n",
    "    else:\n",
    "        _, score = run_and_evaluate_IF('single-IF-' + feature_names[i], mvsa_single_features[i][0], mvsa_single_features[i][1],\n",
    "                                     mvsa_single_multimodal_labels,\n",
    "                                     verbose=0, lstm=False)\n",
    "    scores.append(score)\n",
    "    print()\n",
    "\n",
    "df_single_scores_IF = pd.DataFrame(scores, columns=['Loss', 'Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "356e81ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:27:50.794605Z",
     "iopub.status.busy": "2022-07-04T17:27:50.794305Z",
     "iopub.status.idle": "2022-07-04T17:28:49.023151Z",
     "shell.execute_reply": "2022-07-04T17:28:49.022035Z"
    },
    "papermill": {
     "duration": 58.241006,
     "end_time": "2022-07-04T17:28:49.025183",
     "exception": false,
     "start_time": "2022-07-04T17:27:50.784177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVSA-Multiple with Intermediate Fusion\n",
      "\n",
      "MVSA-Multiple: resnet152-bert\n",
      "\n",
      "MVSA-Multiple: resnet152-bert-lstm\n",
      "\n",
      "MVSA-Multiple: densenet201-bert-pos-lstm\n",
      "\n",
      "MVSA-Multiple: densenet201-bert-pos-ner-lstm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MVSA-Multiple with Intermediate Fusion\\n')\n",
    "scores = []\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    print('MVSA-Multiple:', feature_names[i])\n",
    "    if 'lstm' in feature_names[i]:\n",
    "        _, score = run_and_evaluate_IF('multiple-IF-' + feature_names[i], mvsa_multiple_features[i][0], mvsa_multiple_features[i][1], \n",
    "                                     mvsa_multiple_multimodal_labels,\n",
    "                                     verbose=0)\n",
    "    else:\n",
    "        _, score = run_and_evaluate_IF('multiple-IF-' + feature_names[i], mvsa_multiple_features[i][0], mvsa_multiple_features[i][1],\n",
    "                                     mvsa_multiple_multimodal_labels,\n",
    "                                     verbose=0, lstm=False)\n",
    "    scores.append(score)\n",
    "    print()\n",
    "\n",
    "df_multiple_scores_IF = pd.DataFrame(scores, columns=['Loss', 'Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3273d68",
   "metadata": {
    "papermill": {
     "duration": 0.009036,
     "end_time": "2022-07-04T17:28:49.043509",
     "exception": false,
     "start_time": "2022-07-04T17:28:49.034473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03c9fdbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:28:49.063935Z",
     "iopub.status.busy": "2022-07-04T17:28:49.062260Z",
     "iopub.status.idle": "2022-07-04T17:29:26.318413Z",
     "shell.execute_reply": "2022-07-04T17:29:26.317351Z"
    },
    "papermill": {
     "duration": 37.285998,
     "end_time": "2022-07-04T17:29:26.338295",
     "exception": false,
     "start_time": "2022-07-04T17:28:49.052297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVSA-Single with Late Fusion\n",
      "\n",
      "MVSA-Single: resnet152-bert\n",
      "\n",
      "MVSA-Single: resnet152-bert-lstm\n",
      "\n",
      "MVSA-Single: densenet201-bert-pos-lstm\n",
      "\n",
      "MVSA-Single: densenet201-bert-pos-ner-lstm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MVSA-Single with Late Fusion\\n')\n",
    "scores = []\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    print('MVSA-Single:', feature_names[i])\n",
    "    if 'lstm' in feature_names[i]:\n",
    "        score = run_and_evaluate_LF('single-LF-' + feature_names[i], mvsa_single_features[i][0], mvsa_single_features[i][1], \n",
    "                                     mvsa_single_multimodal_labels, mvsa_single_text_labels, mvsa_single_image_labels,\n",
    "                                     verbose=0)\n",
    "    else:\n",
    "        score = run_and_evaluate_LF('single-LF-' + feature_names[i], mvsa_single_features[i][0], mvsa_single_features[i][1],\n",
    "                                     mvsa_single_multimodal_labels, mvsa_single_text_labels, mvsa_single_image_labels,\n",
    "                                     verbose=0, lstm=False)\n",
    "    scores.append(score)\n",
    "    print()\n",
    "\n",
    "df_single_scores_LF = pd.DataFrame(scores, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9eba36e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:29:26.376122Z",
     "iopub.status.busy": "2022-07-04T17:29:26.375786Z",
     "iopub.status.idle": "2022-07-04T17:30:30.454030Z",
     "shell.execute_reply": "2022-07-04T17:30:30.452934Z"
    },
    "papermill": {
     "duration": 64.111346,
     "end_time": "2022-07-04T17:30:30.469664",
     "exception": false,
     "start_time": "2022-07-04T17:29:26.358318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVSA-Multiple with Late Fusion\n",
      "\n",
      "MVSA-Multiple: resnet152-bert\n",
      "\n",
      "MVSA-Multiple: resnet152-bert-lstm\n",
      "\n",
      "MVSA-Multiple: densenet201-bert-pos-lstm\n",
      "\n",
      "MVSA-Multiple: densenet201-bert-pos-ner-lstm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MVSA-Multiple with Late Fusion\\n')\n",
    "scores = []\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    print('MVSA-Multiple:', feature_names[i])\n",
    "    if 'lstm' in feature_names[i]:\n",
    "        score = run_and_evaluate_LF('multiple-LF-' + feature_names[i], mvsa_multiple_features[i][0], mvsa_multiple_features[i][1], \n",
    "                                     mvsa_multiple_multimodal_labels, mvsa_multiple_text_labels, mvsa_multiple_image_labels,\n",
    "                                     verbose=0)\n",
    "    else:\n",
    "        score = run_and_evaluate_LF('multiple-LF-' + feature_names[i], mvsa_multiple_features[i][0], mvsa_multiple_features[i][1],\n",
    "                                     mvsa_multiple_multimodal_labels, mvsa_multiple_text_labels, mvsa_multiple_image_labels,\n",
    "                                     verbose=0, lstm=False)\n",
    "    scores.append(score)\n",
    "    print()\n",
    "\n",
    "df_multiple_scores_LF = pd.DataFrame(scores, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c7031",
   "metadata": {
    "papermill": {
     "duration": 0.02316,
     "end_time": "2022-07-04T17:30:30.519448",
     "exception": false,
     "start_time": "2022-07-04T17:30:30.496288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hybrid Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90e29606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:30:30.550783Z",
     "iopub.status.busy": "2022-07-04T17:30:30.550317Z",
     "iopub.status.idle": "2022-07-04T17:31:36.996167Z",
     "shell.execute_reply": "2022-07-04T17:31:36.994535Z"
    },
    "papermill": {
     "duration": 66.464222,
     "end_time": "2022-07-04T17:31:36.998861",
     "exception": false,
     "start_time": "2022-07-04T17:30:30.534639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVSA-Single with Hybrid Fusion\n",
      "\n",
      "MVSA-Single: resnet152-bert\n",
      "\n",
      "MVSA-Single: resnet152-bert-lstm\n",
      "\n",
      "MVSA-Single: densenet201-bert-pos-lstm\n",
      "\n",
      "MVSA-Single: densenet201-bert-pos-ner-lstm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MVSA-Single with Hybrid Fusion\\n')\n",
    "scores = []\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    print('MVSA-Single:', feature_names[i])\n",
    "    if 'lstm' in feature_names[i]:\n",
    "        score = run_and_evaluate_HF('single-HF-' + feature_names[i], mvsa_single_features[i][0], mvsa_single_features[i][1], \n",
    "                                     mvsa_single_multimodal_labels, mvsa_single_text_labels, mvsa_single_image_labels,\n",
    "                                     verbose=0)\n",
    "    else:\n",
    "        score = run_and_evaluate_HF('single-HF-' + feature_names[i], mvsa_single_features[i][0], mvsa_single_features[i][1],\n",
    "                                     mvsa_single_multimodal_labels, mvsa_single_text_labels, mvsa_single_image_labels,\n",
    "                                     verbose=0, lstm=False)\n",
    "    scores.append(score)\n",
    "    print()\n",
    "\n",
    "df_single_scores_HF = pd.DataFrame(scores, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17258322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:31:37.023948Z",
     "iopub.status.busy": "2022-07-04T17:31:37.023623Z",
     "iopub.status.idle": "2022-07-04T17:33:31.813585Z",
     "shell.execute_reply": "2022-07-04T17:33:31.810681Z"
    },
    "papermill": {
     "duration": 114.814004,
     "end_time": "2022-07-04T17:33:31.825158",
     "exception": false,
     "start_time": "2022-07-04T17:31:37.011154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVSA-Multiple with Hybrid Fusion\n",
      "\n",
      "MVSA-Multiple: resnet152-bert\n",
      "\n",
      "MVSA-Multiple: resnet152-bert-lstm\n",
      "\n",
      "MVSA-Multiple: densenet201-bert-pos-lstm\n",
      "\n",
      "MVSA-Multiple: densenet201-bert-pos-ner-lstm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MVSA-Multiple with Hybrid Fusion\\n')\n",
    "scores = []\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    print('MVSA-Multiple:', feature_names[i])\n",
    "    if 'lstm' in feature_names[i]:\n",
    "        score = run_and_evaluate_HF('multiple-HF-' + feature_names[i], mvsa_multiple_features[i][0], mvsa_multiple_features[i][1], \n",
    "                                     mvsa_multiple_multimodal_labels, mvsa_multiple_text_labels, mvsa_multiple_image_labels,\n",
    "                                     verbose=0)\n",
    "    else:\n",
    "        score = run_and_evaluate_HF('multiple-HF-' + feature_names[i], mvsa_multiple_features[i][0], mvsa_multiple_features[i][1],\n",
    "                                     mvsa_multiple_multimodal_labels, mvsa_multiple_text_labels, mvsa_multiple_image_labels,\n",
    "                                     verbose=0, lstm=False)\n",
    "    scores.append(score)\n",
    "    print()\n",
    "\n",
    "df_multiple_scores_HF = pd.DataFrame(scores, columns=['Accuracy', 'F1-macro', 'F1-weighted'], index=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f61012",
   "metadata": {
    "papermill": {
     "duration": 0.011027,
     "end_time": "2022-07-04T17:33:31.847697",
     "exception": false,
     "start_time": "2022-07-04T17:33:31.836670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e436030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:33:31.869876Z",
     "iopub.status.busy": "2022-07-04T17:33:31.869571Z",
     "iopub.status.idle": "2022-07-04T17:33:31.966115Z",
     "shell.execute_reply": "2022-07-04T17:33:31.965182Z"
    },
    "papermill": {
     "duration": 0.109912,
     "end_time": "2022-07-04T17:33:31.968048",
     "exception": false,
     "start_time": "2022-07-04T17:33:31.858136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate Fusion with Original Labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\"><tr><td style=\"text-align:center\">MVSA-Single</td><td style=\"text-align:center\">MVSA-Multiple</td></tr><tr><td style=\"vertical-align:top\"> <style type=\"text/css\">\n",
       "#T_c7267_row0_col0, #T_c7267_row1_col0, #T_c7267_row1_col1, #T_c7267_row1_col2 {\n",
       "  color: tomato;\n",
       "}\n",
       "#T_c7267_row2_col0, #T_c7267_row2_col2, #T_c7267_row3_col1 {\n",
       "  color: lawngreen;\n",
       "}\n",
       "</style>\n",
       "<table style=\"display:inline\" id=\"T_c7267_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col1\" >F1-macro</th>\n",
       "      <th class=\"col_heading level0 col2\" >F1-weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c7267_level0_row0\" class=\"row_heading level0 row0\" >resnet152-bert</th>\n",
       "      <td id=\"T_c7267_row0_col0\" class=\"data row0 col0\" >0.603104</td>\n",
       "      <td id=\"T_c7267_row0_col1\" class=\"data row0 col1\" >0.280481</td>\n",
       "      <td id=\"T_c7267_row0_col2\" class=\"data row0 col2\" >0.482997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7267_level0_row1\" class=\"row_heading level0 row1\" >resnet152-bert-lstm</th>\n",
       "      <td id=\"T_c7267_row1_col0\" class=\"data row1 col0\" >0.603104</td>\n",
       "      <td id=\"T_c7267_row1_col1\" class=\"data row1 col1\" >0.250807</td>\n",
       "      <td id=\"T_c7267_row1_col2\" class=\"data row1 col2\" >0.453788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7267_level0_row2\" class=\"row_heading level0 row2\" >densenet201-bert-pos-lstm</th>\n",
       "      <td id=\"T_c7267_row2_col0\" class=\"data row2 col0\" >0.685144</td>\n",
       "      <td id=\"T_c7267_row2_col1\" class=\"data row2 col1\" >0.506248</td>\n",
       "      <td id=\"T_c7267_row2_col2\" class=\"data row2 col2\" >0.683706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c7267_level0_row3\" class=\"row_heading level0 row3\" >densenet201-bert-pos-ner-lstm</th>\n",
       "      <td id=\"T_c7267_row3_col0\" class=\"data row3 col0\" >0.671840</td>\n",
       "      <td id=\"T_c7267_row3_col1\" class=\"data row3 col1\" >0.512758</td>\n",
       "      <td id=\"T_c7267_row3_col2\" class=\"data row3 col2\" >0.672824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">\n",
       "</td><td style=\"vertical-align:top\"> <style type=\"text/css\">\n",
       "#T_4b13c_row1_col0, #T_4b13c_row1_col1, #T_4b13c_row1_col2 {\n",
       "  color: tomato;\n",
       "}\n",
       "#T_4b13c_row2_col0, #T_4b13c_row3_col1, #T_4b13c_row3_col2 {\n",
       "  color: lawngreen;\n",
       "}\n",
       "</style>\n",
       "<table style=\"display:inline\" id=\"T_4b13c_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col1\" >F1-macro</th>\n",
       "      <th class=\"col_heading level0 col2\" >F1-weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4b13c_level0_row0\" class=\"row_heading level0 row0\" >resnet152-bert</th>\n",
       "      <td id=\"T_4b13c_row0_col0\" class=\"data row0 col0\" >0.641011</td>\n",
       "      <td id=\"T_4b13c_row0_col1\" class=\"data row0 col1\" >0.263537</td>\n",
       "      <td id=\"T_4b13c_row0_col2\" class=\"data row0 col2\" >0.502002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b13c_level0_row1\" class=\"row_heading level0 row1\" >resnet152-bert-lstm</th>\n",
       "      <td id=\"T_4b13c_row1_col0\" class=\"data row1 col0\" >0.639248</td>\n",
       "      <td id=\"T_4b13c_row1_col1\" class=\"data row1 col1\" >0.259976</td>\n",
       "      <td id=\"T_4b13c_row1_col2\" class=\"data row1 col2\" >0.499026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b13c_level0_row2\" class=\"row_heading level0 row2\" >densenet201-bert-pos-lstm</th>\n",
       "      <td id=\"T_4b13c_row2_col0\" class=\"data row2 col0\" >0.662162</td>\n",
       "      <td id=\"T_4b13c_row2_col1\" class=\"data row2 col1\" >0.441042</td>\n",
       "      <td id=\"T_4b13c_row2_col2\" class=\"data row2 col2\" >0.598979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b13c_level0_row3\" class=\"row_heading level0 row3\" >densenet201-bert-pos-ner-lstm</th>\n",
       "      <td id=\"T_4b13c_row3_col0\" class=\"data row3 col0\" >0.650999</td>\n",
       "      <td id=\"T_4b13c_row3_col1\" class=\"data row3 col1\" >0.509096</td>\n",
       "      <td id=\"T_4b13c_row3_col2\" class=\"data row3 col2\" >0.631882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">\n",
       "</td></tr></table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Intermediate Fusion with Original Labels')\n",
    "display_dataframes((style_dataframe(df_single_scores_IF.drop(columns=['Loss'])), style_dataframe(df_multiple_scores_IF.drop(columns=['Loss']))), \n",
    "                   names=['MVSA-Single', 'MVSA-Multiple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1127a5e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:33:31.991972Z",
     "iopub.status.busy": "2022-07-04T17:33:31.990166Z",
     "iopub.status.idle": "2022-07-04T17:33:32.020205Z",
     "shell.execute_reply": "2022-07-04T17:33:32.017936Z"
    },
    "papermill": {
     "duration": 0.043318,
     "end_time": "2022-07-04T17:33:32.022269",
     "exception": false,
     "start_time": "2022-07-04T17:33:31.978951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Fusion with Original Labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\"><tr><td style=\"text-align:center\">MVSA-Single</td><td style=\"text-align:center\">MVSA-Multiple</td></tr><tr><td style=\"vertical-align:top\"> <style type=\"text/css\">\n",
       "#T_e758a_row0_col0, #T_e758a_row0_col1, #T_e758a_row0_col2 {\n",
       "  color: tomato;\n",
       "}\n",
       "#T_e758a_row3_col0, #T_e758a_row3_col1, #T_e758a_row3_col2 {\n",
       "  color: lawngreen;\n",
       "}\n",
       "</style>\n",
       "<table style=\"display:inline\" id=\"T_e758a_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col1\" >F1-macro</th>\n",
       "      <th class=\"col_heading level0 col2\" >F1-weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e758a_level0_row0\" class=\"row_heading level0 row0\" >resnet152-bert</th>\n",
       "      <td id=\"T_e758a_row0_col0\" class=\"data row0 col0\" >0.421286</td>\n",
       "      <td id=\"T_e758a_row0_col1\" class=\"data row0 col1\" >0.382211</td>\n",
       "      <td id=\"T_e758a_row0_col2\" class=\"data row0 col2\" >0.511792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e758a_level0_row1\" class=\"row_heading level0 row1\" >resnet152-bert-lstm</th>\n",
       "      <td id=\"T_e758a_row1_col0\" class=\"data row1 col0\" >0.445676</td>\n",
       "      <td id=\"T_e758a_row1_col1\" class=\"data row1 col1\" >0.389558</td>\n",
       "      <td id=\"T_e758a_row1_col2\" class=\"data row1 col2\" >0.527226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e758a_level0_row2\" class=\"row_heading level0 row2\" >densenet201-bert-pos-lstm</th>\n",
       "      <td id=\"T_e758a_row2_col0\" class=\"data row2 col0\" >0.481153</td>\n",
       "      <td id=\"T_e758a_row2_col1\" class=\"data row2 col1\" >0.415987</td>\n",
       "      <td id=\"T_e758a_row2_col2\" class=\"data row2 col2\" >0.556524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e758a_level0_row3\" class=\"row_heading level0 row3\" >densenet201-bert-pos-ner-lstm</th>\n",
       "      <td id=\"T_e758a_row3_col0\" class=\"data row3 col0\" >0.514412</td>\n",
       "      <td id=\"T_e758a_row3_col1\" class=\"data row3 col1\" >0.439849</td>\n",
       "      <td id=\"T_e758a_row3_col2\" class=\"data row3 col2\" >0.585377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">\n",
       "</td><td style=\"vertical-align:top\"> <style type=\"text/css\">\n",
       "#T_4ae53_row0_col0, #T_4ae53_row1_col1, #T_4ae53_row1_col2 {\n",
       "  color: tomato;\n",
       "}\n",
       "#T_4ae53_row0_col1, #T_4ae53_row1_col0, #T_4ae53_row2_col2 {\n",
       "  color: lawngreen;\n",
       "}\n",
       "</style>\n",
       "<table style=\"display:inline\" id=\"T_4ae53_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col1\" >F1-macro</th>\n",
       "      <th class=\"col_heading level0 col2\" >F1-weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4ae53_level0_row0\" class=\"row_heading level0 row0\" >resnet152-bert</th>\n",
       "      <td id=\"T_4ae53_row0_col0\" class=\"data row0 col0\" >0.638660</td>\n",
       "      <td id=\"T_4ae53_row0_col1\" class=\"data row0 col1\" >0.430698</td>\n",
       "      <td id=\"T_4ae53_row0_col2\" class=\"data row0 col2\" >0.603286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ae53_level0_row1\" class=\"row_heading level0 row1\" >resnet152-bert-lstm</th>\n",
       "      <td id=\"T_4ae53_row1_col0\" class=\"data row1 col0\" >0.651586</td>\n",
       "      <td id=\"T_4ae53_row1_col1\" class=\"data row1 col1\" >0.401675</td>\n",
       "      <td id=\"T_4ae53_row1_col2\" class=\"data row1 col2\" >0.592081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ae53_level0_row2\" class=\"row_heading level0 row2\" >densenet201-bert-pos-lstm</th>\n",
       "      <td id=\"T_4ae53_row2_col0\" class=\"data row2 col0\" >0.643361</td>\n",
       "      <td id=\"T_4ae53_row2_col1\" class=\"data row2 col1\" >0.429667</td>\n",
       "      <td id=\"T_4ae53_row2_col2\" class=\"data row2 col2\" >0.609638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ae53_level0_row3\" class=\"row_heading level0 row3\" >densenet201-bert-pos-ner-lstm</th>\n",
       "      <td id=\"T_4ae53_row3_col0\" class=\"data row3 col0\" >0.643361</td>\n",
       "      <td id=\"T_4ae53_row3_col1\" class=\"data row3 col1\" >0.429770</td>\n",
       "      <td id=\"T_4ae53_row3_col2\" class=\"data row3 col2\" >0.609160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">\n",
       "</td></tr></table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Late Fusion with Original Labels')\n",
    "display_dataframes((style_dataframe(df_single_scores_LF), style_dataframe(df_multiple_scores_LF)), \n",
    "                   names=['MVSA-Single', 'MVSA-Multiple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27fce90b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:33:32.050777Z",
     "iopub.status.busy": "2022-07-04T17:33:32.050368Z",
     "iopub.status.idle": "2022-07-04T17:33:32.077914Z",
     "shell.execute_reply": "2022-07-04T17:33:32.076451Z"
    },
    "papermill": {
     "duration": 0.046307,
     "end_time": "2022-07-04T17:33:32.080398",
     "exception": false,
     "start_time": "2022-07-04T17:33:32.034091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Fusion with Original Labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\"><tr><td style=\"text-align:center\">MVSA-Single</td><td style=\"text-align:center\">MVSA-Multiple</td></tr><tr><td style=\"vertical-align:top\"> <style type=\"text/css\">\n",
       "#T_02841_row1_col0, #T_02841_row1_col1, #T_02841_row1_col2 {\n",
       "  color: tomato;\n",
       "}\n",
       "#T_02841_row2_col0, #T_02841_row2_col1, #T_02841_row2_col2 {\n",
       "  color: lawngreen;\n",
       "}\n",
       "</style>\n",
       "<table style=\"display:inline\" id=\"T_02841_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col1\" >F1-macro</th>\n",
       "      <th class=\"col_heading level0 col2\" >F1-weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_02841_level0_row0\" class=\"row_heading level0 row0\" >resnet152-bert</th>\n",
       "      <td id=\"T_02841_row0_col0\" class=\"data row0 col0\" >0.541020</td>\n",
       "      <td id=\"T_02841_row0_col1\" class=\"data row0 col1\" >0.393798</td>\n",
       "      <td id=\"T_02841_row0_col2\" class=\"data row0 col2\" >0.549867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02841_level0_row1\" class=\"row_heading level0 row1\" >resnet152-bert-lstm</th>\n",
       "      <td id=\"T_02841_row1_col0\" class=\"data row1 col0\" >0.514412</td>\n",
       "      <td id=\"T_02841_row1_col1\" class=\"data row1 col1\" >0.379336</td>\n",
       "      <td id=\"T_02841_row1_col2\" class=\"data row1 col2\" >0.532062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02841_level0_row2\" class=\"row_heading level0 row2\" >densenet201-bert-pos-lstm</th>\n",
       "      <td id=\"T_02841_row2_col0\" class=\"data row2 col0\" >0.662971</td>\n",
       "      <td id=\"T_02841_row2_col1\" class=\"data row2 col1\" >0.513725</td>\n",
       "      <td id=\"T_02841_row2_col2\" class=\"data row2 col2\" >0.685092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02841_level0_row3\" class=\"row_heading level0 row3\" >densenet201-bert-pos-ner-lstm</th>\n",
       "      <td id=\"T_02841_row3_col0\" class=\"data row3 col0\" >0.636364</td>\n",
       "      <td id=\"T_02841_row3_col1\" class=\"data row3 col1\" >0.499748</td>\n",
       "      <td id=\"T_02841_row3_col2\" class=\"data row3 col2\" >0.672227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">\n",
       "</td><td style=\"vertical-align:top\"> <style type=\"text/css\">\n",
       "#T_ebd17_row0_col0, #T_ebd17_row1_col1, #T_ebd17_row1_col2 {\n",
       "  color: tomato;\n",
       "}\n",
       "#T_ebd17_row2_col0, #T_ebd17_row2_col1, #T_ebd17_row2_col2 {\n",
       "  color: lawngreen;\n",
       "}\n",
       "</style>\n",
       "<table style=\"display:inline\" id=\"T_ebd17_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col1\" >F1-macro</th>\n",
       "      <th class=\"col_heading level0 col2\" >F1-weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ebd17_level0_row0\" class=\"row_heading level0 row0\" >resnet152-bert</th>\n",
       "      <td id=\"T_ebd17_row0_col0\" class=\"data row0 col0\" >0.643948</td>\n",
       "      <td id=\"T_ebd17_row0_col1\" class=\"data row0 col1\" >0.283736</td>\n",
       "      <td id=\"T_ebd17_row0_col2\" class=\"data row0 col2\" >0.517595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ebd17_level0_row1\" class=\"row_heading level0 row1\" >resnet152-bert-lstm</th>\n",
       "      <td id=\"T_ebd17_row1_col0\" class=\"data row1 col0\" >0.644536</td>\n",
       "      <td id=\"T_ebd17_row1_col1\" class=\"data row1 col1\" >0.280952</td>\n",
       "      <td id=\"T_ebd17_row1_col2\" class=\"data row1 col2\" >0.515315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ebd17_level0_row2\" class=\"row_heading level0 row2\" >densenet201-bert-pos-lstm</th>\n",
       "      <td id=\"T_ebd17_row2_col0\" class=\"data row2 col0\" >0.663925</td>\n",
       "      <td id=\"T_ebd17_row2_col1\" class=\"data row2 col1\" >0.457360</td>\n",
       "      <td id=\"T_ebd17_row2_col2\" class=\"data row2 col2\" >0.621682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ebd17_level0_row3\" class=\"row_heading level0 row3\" >densenet201-bert-pos-ner-lstm</th>\n",
       "      <td id=\"T_ebd17_row3_col0\" class=\"data row3 col0\" >0.652174</td>\n",
       "      <td id=\"T_ebd17_row3_col1\" class=\"data row3 col1\" >0.434773</td>\n",
       "      <td id=\"T_ebd17_row3_col2\" class=\"data row3 col2\" >0.605224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">\n",
       "</td></tr></table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Hybrid Fusion with Original Labels')\n",
    "display_dataframes((style_dataframe(df_single_scores_HF), style_dataframe(df_multiple_scores_HF)), \n",
    "                   names=['MVSA-Single', 'MVSA-Multiple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087047fc",
   "metadata": {
    "papermill": {
     "duration": 0.011198,
     "end_time": "2022-07-04T17:33:32.102935",
     "exception": false,
     "start_time": "2022-07-04T17:33:32.091737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "799571a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T17:33:32.127514Z",
     "iopub.status.busy": "2022-07-04T17:33:32.127229Z",
     "iopub.status.idle": "2022-07-04T17:33:32.133649Z",
     "shell.execute_reply": "2022-07-04T17:33:32.132674Z"
    },
    "papermill": {
     "duration": 0.020591,
     "end_time": "2022-07-04T17:33:32.135575",
     "exception": false,
     "start_time": "2022-07-04T17:33:32.114984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def run_and_evaluate_HF_no_lstm(name, X1, X2, y, y1, y2, verbose=0):\n",
    "#     ''' \n",
    "#     X1: text input\n",
    "#     X2: image input\n",
    "#     y: multimodal labels\n",
    "#     y1: text labels\n",
    "#     y2: image labels\n",
    "#     verbose: 0 or 1 to print tracking on progress\n",
    "#     '''\n",
    "#     y = le.fit_transform(y)\n",
    "#     y = to_categorical(np.asarray(y))\n",
    "    \n",
    "#     y1 = le.fit_transform(y1)\n",
    "#     y1 = to_categorical(np.asarray(y1))\n",
    "    \n",
    "#     y2 = le.fit_transform(y2)\n",
    "#     y2 = to_categorical(np.asarray(y2))\n",
    "    \n",
    "#     X1_train, X1_val, X1_test = split_data(X1, VALIDATION_SPLIT)\n",
    "#     X2_train, X2_val, X2_test = split_data(X2, VALIDATION_SPLIT)\n",
    "#     y_train, y_val, y_test = split_data(y, VALIDATION_SPLIT)\n",
    "#     y1_train, y1_val, y1_test = split_data(y1, VALIDATION_SPLIT)\n",
    "#     y2_train, y2_val, y2_test = split_data(y2, VALIDATION_SPLIT)\n",
    "\n",
    "#     model_text = create_model_text_no_lstm(X1_train.shape[1:])\n",
    "#     model_image = create_model_image(X2_train.shape[1:])\n",
    "#     model_IF = create_model_IF_no_lstm(X1_train.shape[1:], X2_train.shape[1:])\n",
    "\n",
    "#     early_stopping1 = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n",
    "#     early_stopping2 = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n",
    "#     early_stopping3 = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=EARLY_STOPPING)\n",
    "\n",
    "#     checkpoint_text = ModelCheckpoint('./model_checkpoint/{}-text.h5'.format(name), save_best_only=True, verbose=verbose)\n",
    "#     checkpoint_image = ModelCheckpoint('./model_checkpoint/{}-image.h5'.format(name), save_best_only=True, verbose=verbose)\n",
    "#     checkpoint_IF = ModelCheckpoint('./model_checkpoint/{}-IF.h5'.format(name), save_best_only=True, verbose=verbose)\n",
    "\n",
    "#     history_text = model_text.fit(X1_train, y1_train, validation_data=(X1_val, y1_val), \n",
    "#                         epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n",
    "#                         callbacks=[checkpoint_text, early_stopping1])\n",
    "    \n",
    "#     history_image = model_image.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), \n",
    "#                         epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n",
    "#                         callbacks=[checkpoint_image, early_stopping2])\n",
    "    \n",
    "#     history_IF = model_IF.fit([X1_train, X2_train], y_train, validation_data=([X1_val, X2_val], y_val), \n",
    "#                         epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=verbose,\n",
    "#                         callbacks=[checkpoint_IF, early_stopping3])\n",
    "    \n",
    "#     best_val_loss_text = np.min(history_text.history['val_loss'])\n",
    "#     best_val_loss_image = np.min(history_image.history['val_loss'])\n",
    "#     best_val_loss_IF = np.min(history_IF.history['val_loss'])\n",
    "    \n",
    "#     weights = get_average_weights(best_val_loss_text, best_val_loss_image, best_val_loss_IF,\n",
    "#                                   inverse=True)\n",
    "\n",
    "#     model_text = load_model('./model_checkpoint/{}-text.h5'.format(name))\n",
    "#     model_image = load_model('./model_checkpoint/{}-image.h5'.format(name))\n",
    "#     model_IF = load_model('./model_checkpoint/{}-IF.h5'.format(name))\n",
    "\n",
    "#     y_pred_text = model_text.predict(X1_test)\n",
    "#     y_pred_image = model_image.predict(X2_test)\n",
    "#     y_pred_IF = model_IF.predict([X1_test, X2_test])\n",
    "    \n",
    "#     y_pred = weighted_average(weights, np.asarray([y_pred_text, y_pred_image, y_pred_IF], dtype='float32'))\n",
    "    \n",
    "#     best_epoch_text = np.argmin(history_text.history['val_loss'])\n",
    "#     best_epoch_image = np.argmin(history_image.history['val_loss'])\n",
    "#     best_epoch_IF = np.argmin(history_IF.history['val_loss'])\n",
    "\n",
    "#     print('Checkpoint of text model loaded at epoch:', best_epoch_text)\n",
    "#     print('Checkpoint of image model loaded at epoch:', best_epoch_image)\n",
    "#     print('Checkpoint of IF model loaded at epoch:', best_epoch_IF)\n",
    "\n",
    "#     return evaluate_model_LF(y_test, y_pred, verbose=verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 410.610703,
   "end_time": "2022-07-04T17:33:36.117896",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-04T17:26:45.507193",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
